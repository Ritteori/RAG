MLOps & Инструменты: 
76. Что такое Git? Объясни основные команды (clone, pull, commit, push, 
branch, merge). 
Git — это распределенная система контроля версий, которая отслеживает изменения в 
коде, позволяя работать над проектом одновременно и без конфликтов, а также 
откатываться к любым предыдущим состояниям. 
Основные команды: 
• clone: Создает полную локальную копию удаленного репозитория со всей 
историей. 
• pull: fetch + merge. Скачивает изменения из удаленного репозитория и 
интегрирует их в ваш текущий локальный бранч. 
• commit: Фиксирует набор изменений в файлах, создавая постоянный снимок 
состояния (снепшот) в локальной истории репозитория с комментарием. 
• push: Загружает ваши локальные коммиты в удаленный репозиторий, 
обновляя его. 
• branch: Управляет ветками. Показывает список, создает новые или удаляет 
существующие. Ветки — это изолированные линии разработки для задач/фич. 
• merge: Интегрирует изменения из одной ветки в другую (например, из feature в 
main). Создает коммит слияния, если история разошлась. 
77. Что такое Docker? Зачем он нужен в ML? 
Docker — это платформа для разработки, доставки и запуска приложений в 
контейнерах. Контейнер — это изолированный, легковесный процесс, который 
включает в себя само приложение и все его зависимости (библиотеки, системные 
утилиты, настройки), но разделяет ядро ОС с хост-системой. Это обеспечивает 
идентичность среды выполнения на любой машине. 
Зачем Docker в ML (ключевые боли, которые он решает): 
1. Воспроизводимость экспериментов: Гарантия, что модель, обученная на 
ноутбуке разработчика, будет использовать точно такие же версии Python, 
CUDA, PyTorch, scikit-learn и даже системных библиотек (например, libcblas) на 
сервере тренировки и в продакшене. Решает проблему "работает на моей 
машине". 
2. Упрощение развертывания (деплоя): Модель, упакованная в контейнер 
вместе с REST API (например, на FastAPI), становится самодостаточной, 
версионируемой единицей, которую можно легко запустить на любом сервере, в 
Kubernetes или облачном сервисе (SageMaker, Vertex AI). 
3. Масштабирование: Контейнеры — стандартные единицы для оркестраторов 
(Kubernetes), что позволяет легко масштабировать ML-сервисы под нагрузку. 
4. Управление зависимостями: Позволяет иметь на одном сервере несколько 
изолированных сред для разных моделей с потенциально конфликтующими 
требованиями (например, TensorFlow 1.x и 2.x). 
Итог: Docker в ML — это не просто "удобство", а необходимый инструмент для 
построения надежных, воспроизводимых и масштабируемых ML-пайплайнов и 
сервисов. 
78. Что такое Dockerfile? Из чего он состоит? 
Dockerfile — это текстовый файл с инструкциями для сборки Docker-образа. Он 
описывает, из чего должен состоять образ, шаг за шагом. 
Основные инструкции (в порядке типичного использования): 
1. FROM: Задает базовый образ (например, python:3.9-slim). Это обязательная 
первая инструкция. 
2. WORKDIR: Устанавливает рабочую директорию внутри контейнера для 
последующих команд. 
3. COPY (или ADD): Копирует файлы и директории с хоста (вашего компьютера) 
в файловую систему образа. 
4. RUN: Выполняет команду в shell для модификации образа (например, установка 
пакетов: RUN pip install -r requirements.txt). 
5. ENV: Устанавливает переменные окружения внутри контейнера. 
6. EXPOSE: Документирует порт, который контейнер будет слушать (информация 
для пользователя образа). 
7. CMD (или ENTRYPOINT): Определяет команду, которая будет выполнена при 
запуске контейнера из этого образа. В ML-контексте это может быть запуск 
скрипта обучения или inference-сервера. 
Пример логики: Сначала берем легкий базовый образ с Python, копируем файлы 
проекта, устанавливаем зависимости, и в конце указываем, как запустить приложение. 
Каждая инструкция создает новый слой образа.
79. В чем разница между Docker образом и контейнером? 
Это принципиально разные сущности, аналогичные исполняемому файлу и процессу. 
• Образ (Image) — это шаблон, шаблон только для чтения. Это многослойная 
сборка, созданная из Dockerfile. Каждый слой — это изменение файловой 
системы (установка пакета, копирование файла). Образ статичен, неизменяем и 
хранится в реестре (Docker Hub). Это "упакованное приложение со всеми 
зависимостями". 
• Контейнер (Container) — это запущенный экземпляр образа, процесс. При 
создании контейнера Docker добавляет поверх read-only слоев образа тонкий 
записываемый слой (container layer), в котором живут все изменения во время 
его работы. Контейнер изолирован (имеет свои процессы, сетевой интерфейс) и 
может быть запущен, остановлен, удален. Из одного образа можно запустить 
множество независимых контейнеров. 
Ключевая метафора: Образ — это чертеж дома (Dockerfile -> билд -> образ). 
Контейнер — это построенный по этому чертежу дом, в который заселились люди 
(запустились процессы). Можно построить много одинаковых домов из одного 
чертежа. 
80. Что такое CI/CD? Как это применяется в ML? 
CI/CD (Continuous Integration / Continuous Delivery/Deployment) — это практика и 
набор инструментов для автоматизации сборки, тестирования и развертывания 
изменений кода. 
• CI (Непрерывная интеграция): При пуше/мерже в основную ветку 
автоматически запускается пайплайн, который: 
o Собирает приложение (в ML-контексте — создает Docker-образ). 
o Запускает статический анализ кода (линтеры, форматирование). 
o Запускает тесты: юнит-тесты, интеграционные тесты и, что критично 
для ML, тесты данных и моделей (проверка формата данных, падение 
метрик ниже порога). 
• CD (Непрерывная доставка/развертывание): Если CI прошел успешно, 
автоматически: 
o Выкладывает собранный артефакт (Docker-образ, пакет) в реестр. 
o Разворачивает его в тестовое/промежуточное окружение (staging). 
o (Для Continuous Deployment) — автоматически разворачивает в 
продакшен. Чаще в ML используется Continuous Delivery — 
развертывание в продакшен требует ручного подтверждения. 
Как это применяется в ML (MLOps): 
Пайплайн расширяется специфичными этапами: 
1. Тестирование данных: Проверка схемы, распределения, отсутствия дрейфа 
(data drift) на новых данных. 
2. Тестирование модели: Автоматический перезапуск обучения при изменении 
кода модели или данных. Сравнение метрик новой и предыдущей модели. 
Валидация, что метрики не упали ниже порога. 
3. Воспроизводимость: Пайплайн гарантирует, что артефакт (обученная модель) 
тестируется и доставляется в том же окружении, в котором был обучен. 
4. Поэтапный деплой: Сначала деплой модели на небольшой трафик (canary
развертывание), мониторинг её метрик (качество, latency), и только потом 
полный rollout. 
Итог: В ML CI/CD — это основа для автоматизации, контроля качества и безопасного 
развертывания моделей в продакшен. 
81. Как бы ты организовал пайплайн обучения модели? (Сбор данных -> 
препроцессинг -> обучение -> валидация -> выкладка). 
Я бы организовал его как автоматизированный, воспроизводимый и 
контролируемый по качеству процесс, разбитый на этапы, которые управляются 
кодом (скриптами) и оркестратором. 
1. Сбор данных (Data Ingestion): 
• Что: Автоматический сбор данных из источников (базы данных, файловые 
хранилища, API). 
• Как: Написание скриптов (например, на Python), которые запускаются по 
расписанию через оркестратор пайплайнов (например, Apache Airflow). 
Airflow позволяет визуально описывать зависимости между задачами в виде 
DAG (Directed Acyclic Graph) — это график, где каждая задача — узел, а 
стрелки показывают порядок выполнения. 
• Результат: Сырые данные помещаются в выделенное хранилище (например, 
S3) с версионированием. 
2. Препроцессинг и Feature Engineering (Data Preparation): 
• Что: Очистка данных, обработка выбросов, кодирование категориальных 
признаков, генерация новых фич. 
• Ключевой момент: Все преобразования (например, StandardScaler, 
OneHotEncoder) обучаются (fit) только на тренировочной части данных. 
Полученные объекты-трансформеры сохраняются как артефакты. Это нужно, 
чтобы при инференсе применять те же преобразования, и избежать data leakage 
(утечки информации из теста/будущего в тренировку). 
• Результат: Готовые наборы данных (train/val/test) и сохраненные 
трансформеры. 
3. Обучение модели (Model Training): 
• Что: Обучение модели, подбор гиперпараметров, логирование экспериментов. 
• Как: Этап выполняется в изолированном и воспроизводимом окружении 
(например, Docker-контейнере). Для перебора гиперпараметров использую 
библиотеки вроде Optuna или Hyperopt, которые автоматически ищут лучшую 
комбинацию. Все параметры, метрики и сам код фиксируются в системе 
трекинга экспериментов, например, MLflow. 
• Результат: Обученная модель, сохраненная как артефакт, и полный лог 
эксперимента. 
4. Валидация и тестирование (Model Validation): 
• Что: Оценка качества модели на данных, которые она не видела при обучении 
(на hold-out тестовом наборе). 
• Ключевой момент: Пайплайн должен включать автоматические проверки 
(валидации). Например: "F1-метрика на тесте > 0.85" и "Новая модель не хуже 
предыдущей продакшен-версии по AUC". Если проверки не пройдены — 
пайплайн останавливается, а команда получает алерт. Это защита от выкатки 
плохой модели. 
• Результат: Решение: модель проходит в продакшен или отправляется на 
доработку. 
5. Выкладка (Deployment): 
• Что: Упаковка модели и трансформеров в сервис и развертывание его в 
продакшен-среде. 
• Как: Модель и трансформеры упаковываются в Docker-образ с легковесным 
REST API (например, на FastAPI). Для безопасного обновления используется 
стратегия Canary Deployment — сначала модель разворачивается для 
небольшого процента пользователей (например, 5%), и ее метрики (латентность, 
качество) активно мониторятся. Если все хорошо, релиз расширяется на всех. 
• Результат: Рабочий ML-сервис, доступный для предсказаний. 
Философия: Главное — это автоматизация, контроль качества на каждом этапе и 
воспроизводимость (чтобы любой запуск пайплайна можно было точно повторить с 
теми же результатами). 