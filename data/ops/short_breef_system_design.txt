Раздел 7: Системный дизайн и Продукт 
87. Расскажи, как бы ты построил систему рекомендаций для интернет
магазина? (С высоты птичьего полета). 
Я бы строил ее по классической двухэтапной схеме Retrieval (генерация кандидатов) -> Ranking (ранжирование). 
1. Retrieval (Генерация сотен кандидатов): Быстрыми методами из всего каталога 
отбираем 100-500 товаров. 
• User-based CF: "Похожим на вас пользователям понравилось X". Используем 
прошлые взаимодействия (просмотры, покупки). 
• Item-based CF: "Смотрите наушники? С ними часто берут чехлы". Считаем 
попарные схожести товаров. 
• Популярное/Трендовое: Топ товаров в городе или категории. Решает проблему 
холодного старта. 
• Семантический поиск: Ищем товары, похожие на текст запроса или описание 
просмотренного, используя эмбеддинги (векторные представления) из NLP
модели и векторную БД (FAISS). 
2. Ranking (Точное ранжирование): Из сотен кандидатов ML-модель выбирает 10-20 
лучших. 
• Фичи: Информация о пользователе (история, демография), о товаре (цена, 
популярность, категория), об их взаимодействии (сколько раз видел). 
• Модель: Градиентный бустинг (CatBoost/XGBoost) или нейросеть. Цель — 
предсказать вероятность покупки/клика. 
• Обучение: На исторических данных (был показан товар Y, пользователь 
совершил целевое действие или нет). 
3. Инфраструктура: 
• Данные: Собираем логи всех действий в хранилище (ClickHouse). 
• Паблишинг: Модель ранжирования работает как микросервис (REST API в 
Docker). 
• Оценка: A/B-тесты на живом трафике — главная метрика. Офлайн — точность 
(Precision@k). 
Ключ: Система всегда должна давать релевантный результат, даже для новых 
пользователей (популярное) и новых товаров (контентные фичи). 
88. Как бы ты подошел к задаче классификации спам-писем? 
1. Постановка задачи и метрика 
• Задача: Бинарная классификация (спам / не спам). 
• Ключевая проблема: Сильный дисбаланс классов (спама ~1-5%). Accuracy 
бессмысленна. 
• Основная метрика: F1-score (среднее гармоническое Precision и Recall). 
Выбор порога и финальная метрика зависят от продукта: 
o Если важно не пропустить спам (почта пользователя) → 
максимизируем Recall для класса "спам". 
o Если важно не удалить важное (рассылка компании) → максимизируем 
Precision для класса "спам". 
2. Данные и препроцессинг 
• Источники: Публичные датасеты (SpamAssassin) + внутренняя разметка 
(письма, помеченные пользователями). 
• Препроцессинг текста: 
o Токенизация, приведение к нижнему регистру. 
o Удаление стоп-слов, пунктуации, HTML-тегов. 
o Лемматизация (приведение к начальной форме). 
o Обработка специальных сущностей: замена URL и email на токены 
[URL], [EMAIL]. 
3. Векторизация (Feature Engineering) 
• Базовый подход (прототип, бейзлайн): TF-IDF (мешок слов с учетом 
важности). Легко, интерпретируемо, работает. 
• Мета-признаки: Длина письма, количество ссылок, восклицательных знаков, 
наличие определенных ключевых слов ("акция", "бесплатно"). 
• Продвинутый подход (если нужно качество выше): Использование 
предобученных эмбеддингов (FastText, Word2Vec) или контекстуальных 
эмбеддингов из легкой версии BERT (например, DistilBERT) для получения 
векторного представления всего письма. 
4. Выбор и обучение модели 
• Шаг 1. Простой и объяснимый бейзлайн: Наивный Байес (MultinomialNB) 
или Логистическая регрессия на TF-IDF + мета-признаки. Это даст 
понимание, какие слова важны для решения. 
• Шаг 2. Основная модель: Градиентный бустинг (CatBoost, XGBoost) на тех 
же признаках. Хорошо работает с дисбалансом (задание весов классов), часто 
дает лучшее качество. 
• Шаг 3. (Опционально) Сложная модель: Простая нейросеть (1D-CNN) или 
легкий Transformer, если контекст крайне важен и предыдущие шаги не дали 
нужного качества. 
• Борьба с дисбалансом: Веса классов в функции потерь, SMOTE для генерации 
синтетических примеров, подбор порога классификации по PR-кривой. 
5. Валидация и тестирование 
• Стратифицированная кросс-валидация для сохранения распределения 
классов. 
• Выделение временного холдаута (письма за последнюю неделю) для оценки 
на "свежих" данных, похожих на продакшен. 
• Анализ ошибок: Разбор false positive (хорошие письма в спаме) и false negative 
(пропущенный спам) для улучшения фичей. 
6. Внедрение и мониторинг 
• Упаковка: Пайплайн (препроцессор, векторизатор, модель) в Docker
контейнер с REST API (FastAPI). 
• Постепенный rollout (Canary): Запуск для 1% трафика, сравнение с текущей 
системой. 
• Мониторинг: 
o Качество: Онлайн-метрики (доля писем, помеченных как спам). 
Отслеживание Data Drift (изменение распределения входных слов) и 
Concept Drift (падение точности на новых размеченных данных). 
o Производительность: Время инференса (latency). 
• Активное дообучение: Письма с вероятностью ~0.5 отправляются на 
повторную разметку для периодического обновления модели. 
Ключевой принцип: Начать максимально просто и интерпретируемо, усложнять 
модель только при необходимости, постоянно мониторить в production. 
89. Допустим, твоя модель отлично работает на тренировочных данных, 
но плохо на продакшене. В чем могут быть причины? (Data Drift, 
Concept Drift, неправильный препроцессинг). 
Причин несколько, они часто накладываются. Я разделю их на категории: 
1. Проблемы с самими данными и их обработкой: 
• Data Leak (Утечка данных): Модель невольно получила доступ к данным, 
которых не будет в реальности. Например, в тренировочные фичи попала 
целевая переменная (или её производная) из будущего. Это самая опасная 
причина, так как её сложно обнаружить, кроме как резким падением метрик в 
продакшене. 
• Неправильный препроцессинг/Feature Engineering: Конвейер обработки 
данных для обучения и для инференса разный или неидентичен. Например, в 
продакшен пришли новые категории, которых не было в трейне, и энкодер их 
обработал неправильно. Или статистики для нормализации (среднее, дисперсия) 
были посчитаны по всему датасету, а не только по тренировочной части. 
• Некорректное разбиение на train/test: Разбиение не отражает временной 
природы данных (например, тест хронологически раньше трейна) или не 
стратифицировано. Это создает ложное впечатление о высоком качестве. 
2. Проблемы с моделью и её обобщающей способностью: 
• Переобучение (Overfitting): Модель выучила шум и случайные 
закономерности тренировочного набора, а не общие правила. Признак — 
большой разрыв между метриками на трейне/валидации и на тесте/продакшене. 
Лечится: регуляризация, упрощение модели, увеличение данных, аугментация, 
ранняя остановка. 
• Недообучение (Underfitting): Модель слишком проста для данных. Качество 
плохое и на трейне, и на проде, но часто это менее критично, так как заметно 
сразу. 
3. Проблемы извне (окружающая среда меняется): 
• Data Drift (Дрейф данных): Изменилось распределение входных признаков 
(P(X)). Например, после пандемии изменился профиль покупателей (признаки), 
или в данные стали поступать запросы с новых регионов. 
• Concept Drift (Дрейф концепции): Изменилось связь между признаками и 
целевой переменной (P(Y|X)). То, что раньше было сигналом, теперь стало 
шумом. Например, слово "маска" раньше было маркером медицинского спама, а 
теперь — обычным словом в новостях. 
Мой подход к диагностике: Сначала проверяю pipeline на утечку данных и 
идентичность препроцессинга. Затем анализирую, не произошел ли data drift 
(сравнивая распределения признаков на трейне и в проде). И только потом смотрю на 
модель и гипотезирую о concept drift. 
90. Что такое Data Drift и Concept Drift? Как их обнаружить? 
Определения: 
• Data Drift (Дрейф данных): Изменилось распределение входных признаков 
P(X). Модель получает на вход данные, отличные от тех, на которых обучалась. 
Пример: В приложении для такси изменилась доля поездок из аэропорта 
(признак pickup_location), потому что открыли новый терминал. 
• Concept Drift (Дрейф концепции): Изменилась связь между признаками и 
целевой переменной P(Y|X). Старые паттерны перестали работать. Пример: Во 
время экономического кризиса высокий доход (признак) перестал быть 
надежным индикатором выдачи кредита (таргет). 
Как обнаружить: 
1. Для Data Drift (мониторим постоянно, ground truth не нужен): 
• Статистические тесты: Для числовых признаков — тест Колмогорова
Смирнова, Population Stability Index (PSI). Для категориальных — хи
квадрат. Сравниваем распределение признака в референсном (тренировочном) 
наборе и в продовом батче. 
• Модельный подход: Обучаем бинарный классификатор (например, простой 
логистической регрессии) отличать продовые данные от тренировочных. Если 
модель справляется (AUC высокий) — данные отличаются, есть дрейф. 
• Мониторинг агрегатов: Отслеживаем скользящие средние, моду, процентили 
ключевых признаков на дашборде. 
2. Для Concept Drift (мониторим, как появляются истинные метки): 
• Мониторинг метрик качества: Резкое падение online-метрик (Accuracy, F1, 
Recall) на свежеразмеченных данных (например, по которым уже пришел 
отклик) — прямой сигнал. 
• Детекторы дрейфа: Использование специализированных библиотек (Evidently 
AI, Alibi Detect, River), которые следят за смещением распределения ошибок 
модели или за изменением важности признаков. 
• Контрольные выборки (Golden Dataset): Периодический прогон модели на 
небольшом, но репрезентативном и неизменном наборе данных с истинными 
метками. Если метрики падают здесь, проблема в модели (возможно, дрейф). 
3. Проактивные меры: 
• Система алертинга: Настраиваем алерты при превышении порога PSI для 
ключевых признаков или при падении метрик качества. 
• Регулярное переобучение: Настройка пайплайна на периодическое дообучение 
модели на свежих данных, даже без явных сигналов о дрейфе. 
Итог: Data drift обнаруживаем статистическими методами над входными данными. 
Concept drift обнаруживаем по падению качества на актуальных размеченных 
данных. Автоматизация этого мониторинга — основа стабильной ML-системы в 
продакшене. 
91. Как ты будешь мониторить твою модель в продакшене? (Метрики 
качества, логи, latency). 
Мониторинг строится по четырем ключевым уровням: 
1. Здоровье инфраструктуры и доступность: 
• Латентность (Latency): P50, P95, P99 время отклика модели. Резкий рост — 
сигнал о проблемах с ресурсами (CPU/GPU) или кодом. 
• Ошибки (Error Rate): Процент HTTP 5xx/4xx ошибок инференс-сервиса. 
• Нагрузка (Throughput): Количество запросов в секунду. 
• Ресурсы: Загрузка CPU/GPU, память, сеть контейнера. 
2. Качество входных данных (Data Drift): 
• Распределение ключевых признаков: Отслеживаю Population Stability Index 
(PSI) или тест Колмогорова-Смирнова для числовых признаков, сравнивая 
текущие данные с тренировочным распределением. Алерт при PSI > 0.1-0.2. 
• Появление новых категорий или пропусков в категориальных признаках. 
• Статистики: Скользящие средние, дисперсия основных фичей на дашборде 
(Grafana). 
3. Качество предсказаний (Model Performance): 
• Бизнес-метрики (если есть онлайн-оценка): На основе отложенных меток 
(ground truth), которые приходят с задержкой (например, конверсия после 
клика). Рассчитываю Accuracy, Precision, Recall, F1, AUC на скользящем окне 
(например, за день). Любое значимое падение — алерт. 
• Смещение выходов (Prediction Drift): Распределение предсказанных 
вероятностей или классов. Резкое изменение может указывать на concept drift. 
• Калибровка модели: Для вероятностных моделей проверяю, соответствует ли 
confidence модели реальной точности (Calibration Curve). 
4. Бизнес-индикаторы и интерпретируемость: 
• Влияние на продукт: A/B тесты — сравнение ключевых бизнес-метрик (CTR, 
конверсия, средний чек) между старой и новой моделью. 
• Анализ ошибок: Доля самых "сомнительных" предсказаний (например, где 
вероятность близка к 0.5). Их можно отправлять на ручную проверку (active 
learning). 
• Важность признаков (SHAP values): Мониторинг топ-10 самых влиятельных 
признаков на скользящем окне. Изменение в этом списке может 
сигнализировать о смене паттернов. 
Инструменты: Для метрик инфраструктуры — Prometheus/Grafana. Для 
мониторинга данных и дрейфа — Evidently AI, WhyLogs или кастомные дашборды. 
Для логирования предсказаний и фичей — централизованный лог-стек (ELK/Loki). 
Для экспериментов и модельного реестра — MLflow. 
Философия: Цель — не просто "видеть метрики", а иметь систему автоматических 
алертов, которая предупредит о проблеме раньше, чем её заметят пользователи или 
бизнес.