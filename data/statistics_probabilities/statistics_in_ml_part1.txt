8. Применение в ML 
66.Как используется вероятность в логистической регрессии? 
Логистическая регрессия — это модель, которая предсказывает вероятность 
принадлежности объекта к какому-то классу, чаще всего — к положительному 
(class = 1). 
Модель на выходе даёт не просто 0 или 1, а число от 0 до 1, которое 
интерпретируется как вероятность. 
�
� Как используется эта вероятность? 
1. Классификация: 
Обычно берут порог 0.5. 
Если p>0.5p > 0.5p>0.5 → класс 1, иначе → класс 0. 
2. Ранжирование: 
Когда важен уровень уверенности (например, при кредитном скоринге, 
медицине). 
3. Порог можно менять: 
В задачах с дисбалансом классов (например, если положительный класс 
редкий) можно поставить порог не 0.5, а, например, 0.2. 
4. Использование в loss-функциях: 
Например, бинарная кросс-энтропия работает с вероятностями. 
�
� Маленький пример: 
Допустим, у нас есть модель, которая на вход получает рост и вес человека и 
предсказывает, болен ли он диабетом. 
Модель выдала: 
P(диабет=1)=0.82  
Это значит, с вероятностью 82% человек болен диабетом. 
Если мы используем порог 0.5 — классифицируем как больного. 
Если хотим быть осторожнее, можно поднять порог до 0.9. 
67. Где в ML применяется формула Байеса? 
Формула Байеса позволяет пересчитывать априорные вероятности (что мы 
знаем заранее) в апостериорные вероятности (что мы узнали после получения 
новых данных). 
Ключевое допущение: признаки xix_ixi  условно независимы при заданном 
классе yyy (поэтому и "наивный"). 
Применяется, например, в: 
• Классификации текстов (спам/не спам), 
• Обнаружении фишинга, 
• Простейших baseline-моделях. 
✅ 2. Байесовский вывод в целом 
Формула Байеса используется в: 
• Байесовской регрессии, 
• Байесовских нейронных сетях (Baysian Neural Networks), 
• Генеративных моделях (например, Latent Dirichlet Allocation), 
• Моделях, где важно учитывать неопределённость предсказаний. 
✅ 3. Интерпретация вероятностей 
Байесовский подход позволяет не просто сказать "да/нет", а оценить, насколько 
сильно мы в этом уверены. Это важно для: 
• Ранжирования результатов, 
• Медицинской диагностики, 
• Финансовых систем. 
68.Почему важно понимать распределения признаков? 
В ML анализ распределений признаков (feature distributions) помогает: 
✅ 1. Обнаруживать выбросы 
Ты правильно заметил: если в данные затесались необычные экземпляры 
(например, тропические животные в выборке северных), то метрики и обучение 
могут исказиться. 
Пример: 
Если все признаки (например, "температура среды") лежат около -30°C, и вдруг 
появляется +30°C — это может: 
• Увеличить дисперсию, 
• Сильно повлиять на среднее (если использовать MSE), 
• Нарушить обучение модели. 
✅ 2. Выбирать правильные метрики и модели 
• Например, MSE чувствительна к выбросам, как ты написал. 
• Если признак распределён не нормально, то логистическая регрессия или 
линейная модель может плохо работать. 
✅ 3. Понимать необходимость преобразований 
• Логарифмирование, стандартизация, нормализация — всё это зависит от 
формы распределения. 
• Некоторые модели (например, деревья) не чувствительны к масштабу, а 
другие (например, SVM) — чувствительны. 
✅ 4. Проверка предпосылок статистических методов 
Некоторые модели и тесты предполагают нормальность или однородность 
дисперсий — если распределения "кривые", то предпосылки нарушаются. 
69.Почему важно контролировать смещённость выборки? 
Смещённая выборка — это выборка, в которой какие-то группы данных 
представлены непропорционально (например, слишком мало женщин в 
медицинском исследовании или одни только фото собак в датасете для 
классификации животных). 
Почему важно это контролировать: 
1. Модель будет плохо обобщаться 
Если модель обучается на смещённой выборке, она «привыкает» к 
перекосу и начинает игнорировать или неправильно обрабатывать 
редкие, но важные случаи. Например, если обучать классификатор 
болезней почти только на здоровых пациентах — он не научится находить 
болезнь. 
2. Искажение метрик качества 
Смещённая выборка часто даёт ложное чувство высокой точности, 
особенно при несбалансированных классах. Например, модель может 
просто предсказывать «0» всегда и иметь 95% accuracy, если класс «1» — 
редкий. 
3. Несправедливость и дискриминация 
Особенно важно в задачах, связанных с людьми: если модель тренируется 
на данных, где доминирует одна этническая группа, возраст, пол и т.п., она 
будет дискриминировать менее представленные группы. 
4. Снижается устойчивость модели 
Смещённость делает модель чувствительной к данным, которые она не 
видела, — особенно в реальных условиях, где данные могут сильно 
отличаться от тренировочных. 
Итог: 
Контроль за смещённостью выборки — это основа качественного и честного ML. 
Это делается с помощью стратифицированного сэмплинга, 
oversampling/undersampling, сбалансированных метрик (F1, AUC), анализов 
распределений и пр. 
70.Как понять, что модель переобучилась по p-value? 
Обычно p-value используется не напрямую для оценки переобучения, но его 
можно косвенно использовать в A/B-тестах, чтобы заметить, что модель даёт 
"слишком хорошие" результаты на тренировке и плохие на тесте. 
�
� Сценарий: 
Допустим, ты сравниваешь две модели (или версию модели до/после изменений) 
и проверяешь гипотезу: 
• H₀ (нулевая гипотеза): нет улучшений, модели одинаково хороши 
• H₁ (альтернатива): новая модель лучше 
Ты обучаешь модель, получаешь p-value = 0.001 → это значит, что есть 
статистически значимое улучшение. 
Но!    
Если p-value сильно низкое на тренировке, а высокое на тесте, это 
означает: 
• модель переобучилась; 
• она «выучила» тренировочные данные, но не обобщает на новые; 
• значит, улучшения — не статистически значимы на тесте. 
�
� Вывод: 
По p-value само по себе переобучение не видно, но: 
• если p-value малое на train и большое на test — это может быть 
признаком переобучения; 
• ещё важен размер выборки — на маленьких выборках p-value может врать; 
• поэтому p-value в ML чаще используется в A/B тестах, а переобучение 
определяют с помощью: 
o разницы между train и test метриками (например, accuracy, loss), 
o визуализации лосса, 
o регуляризации и кросс-валидации 