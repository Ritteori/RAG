Раздел 1: Классическое Machine Learning (самая важная часть) 
1. В чем разница между машинным обучением и глубинным 
обучением? 
ML — общее понятие, DL — его часть (подмножество). 
Критерий 
Классическое ML 
Алгоритмы 
Линейные модели, деревья, 
SVM, бустинг 
Глубокое обучение (DL) 
Нейросети (CNN, RNN, 
трансформеры) 
Интерпретируе
мость 
Высокая («белый ящик») 
Низкая («чёрный ящик») 
Данные / 
Признаки 
Требует ручной feature 
engineering 
Самостоятельно учит иерархию 
признаков 
Ресурсы 
Эффективно на малых данных, 
CPU 
Требует много данных и GPU 
Суть: ML — для структурированных данных и интерпретации, DL — для 
неструктурированных (изображения, текст) и максимума качества. 
2. Объясните разницу между обучением с учителем (Supervised) и без 
учителя (Unsupervised). Приведите примеры алгоритмов для 
каждого. 
Тип 
Наличие 
разметки 
Цель 
Алгоритмы / 
Методы 
Примеры 
задач 
С 
учителем 
(Supervise
d) 
Есть (X → 
y) 
Научиться 
предсказыват
ь целевую 
переменную 
по примерам 
Классификация
, Регрессия 
Без 
учителя 
Нет (только 
X) 
Найти 
скрытые 
структуры/зак
Линейная/Логистичес
кая регрессия, 
Деревья, SVM, CNN, 
Transformer 
Кластеризация, 
Понижение 
размерности 
K-Means, DBSCAN, 
PCA, Autoencoders 
(AE/VAE) 
(Unsupervi
sed) 
ономерности 
в данных 
С 
подкрепле
нием 
(Reinforce
ment) 
Игры, 
Робототехника, 
Нет (есть 
среда) 
Научиться 
стратегии 
действий для 
максимизации 
награды 
RLHF 
Q-Learning, Policy 
Gradients 
3. Что такое переобучение (Overfitting)? Как с ним бороться? (Жди 
вопрос про конкретные методы). 
Что это: Модель слишком сложна и "зазубрила" тренировочные данные, включая 
шумы и выбросы. Результат — низкая ошибка на тренировке, но высокая на тесте 
(плохая генерализация). 
Причина в терминах Bias-Variance: Низкий bias, но очень высокий variance. 
Методы борьбы: 
1. Регуляризация: Добавление штрафа за сложность весов (L1/Lasso, L2/Ridge). 
2. Увеличение датасета: Сбор больше данных — один из самых эффективных 
методов. 
3. Ранняя остановка (Early Stopping): Остановка обучения, когда ошибка на 
валидации перестает улучшаться. 
4. Упрощение модели: Уменьшение глубины деревьев, количества 
слоев/нейронов в сети. 
5. Аугментация данных: Искусственное расширение данных (для изображений, 
текста). 
6. Ансамблирование: Использование бэггинга (Random Forest), который хорошо 
подавляет variance. 
7. Dropout: Случайное "выключение" нейронов во время обучения (для 
нейросетей). 
4. Что такое недообучение (Underfitting)? Как с ним бороться? 
Что это: Модель слишком проста и не может выучить основные закономерности в 
данных. Результат — высокая ошибка и на тренировке, и на тесте. 
Причина в терминах Bias-Variance: Высокий bias, низкий variance. 
Методы борьбы: 
1. Увеличение сложности модели: 
a. Для нейросетей: добавление слоев/нейронов. 
b. Для деревьев: увеличение глубины. 
c. Для линейных моделей: добавление полиномиальных признаков. 
2. Увеличение времени обучения: Больше эпох для нейросетей, пока кривая 
обучения не выйдет на плато. 
3. Уменьшение регуляризации: Снижение силы L1/L2 штрафов. 
4. Улучшение feature engineering: Создание более качественных и 
информативных признаков. 
5. Использование более сложных моделей: Переход от, например, линейной 
регрессии к бустингу. 
5. Что такое Bias-Variance Tradeoff? Объясни на примере. 
Определение: Фундаментальный компромисс в ML, при котором невозможно 
одновременно минимизировать две ошибки: 
• Bias (Смещение): Ошибка, вызванная слишком простыми предположениями 
модели. (Недообучение). 
• Variance (Разброс): Ошибка, вызванная чувствительностью модели к 
небольшим колебаниям в тренировочных данных. (Переобучение). 
Цель: Найти оптимальную сложность модели, которая минимизирует суммарную 
ошибку (bias² + variance + noise). 
Пример: Предсказание цены дома 
• Высокий Bias (Недообучение): Используем линейную регрессию, где цена 
зависит только от площади. Модель слишком проста, чтобы учесть другие 
важные факторы (район, количество комнат). Она будет стабильно ошибаться 
(высокий bias) и на тренировке, и на тесте, но ее предсказания будут 
устойчивыми (низкий variance). Это недообучение. 
• Высокий Variance (Переобучение): Используем очень глубокое дерево 
решений, которое запоминает каждую квартиру в тренировочном наборе, 
включая все аномалии и шумы. На тренировке ошибка будет почти нулевая 
(низкий bias), но на новых данных из того же района она даст совершенно дикие 
предсказания (высокий variance). Это переобучение. 
• Оптимум (Tradeoff): Используем случайный лес или градиентный бустинг с 
хорошо подобранными параметрами. Модель достаточно сложна, чтобы 
уловить основные зависимости (цена зависит от площади, района, ремонта), но 
не настолько, чтобы запомнить шумы. Мы находим баланс, где суммарная 
ошибка (bias² + variance) минимальна. 
6. Как вы выбираете метрику для вашей задачи? (Например, почему 
Accuracy может быть плоха для несбалансированных данных?). 
Общий принцип: Метрика должна соответствовать бизнес-цели задачи. 
1. Регрессия (предсказание числа): 
• MSE (Mean Squared Error): Сильно штрафует за большие ошибки. 
• MAE (Mean Absolute Error): Интерпретируемость — средняя ошибка в 
единицах измерения. 
• R² (R-squared): Доля дисперсии, объясненная моделью. 
2. Классификация: 
• Сбалансированные данные: Accuracy (доля верных ответов). 
• Несбалансированные данные: Accuracy бесполезна! Нужны метрики, 
учитывающие классы: 
o Precision (Точность): = TP / (TP + FP) 
▪ "Насколько мы можем доверять положительному прогнозу?" 
▪ Пример: В спам-фильтрации важно не пометить нормальное 
письмо как спам (минимизировать FP). 
o Recall (Полнота): = TP / (TP + FN) 
▪ "Какую долю реально больных мы нашли?" 
▪ Пример: В диагностике рака важно найти всех больных 
(минимизировать FN). 
o F1-Score (F-мера): = 2 * (Precision * Recall) / (Precision + Recall) 
▪ Гармоническое среднее между Precision и Recall. Используется, 
когда нужно найти баланс. 
• ROC-AUC: Показывает, насколько хорошо модель отделяет классы друг от 
друга на всех порогах. Хорош для сбалансированных задач. 
• Precision-Recall AUC: Лучше подходит для несбалансированных данных, так 
как фокусируется на качестве предсказания позитивного класса. 
7. Что такое регуляризация (Regularization)? Зачем она нужна и как 
работает (L1 - Lasso, L2 - Ridge)? 
Цель: Борьба с переобучением путем ограничения сложности модели. Штрафует 
модель за слишком большие веса. 
Как работает: К исходной функции потерь (например, MSE) добавляется штрафной 
член (penalty term). 
• L1-регуляризация (Lasso): Loss = Ошибка + α * Σ|w_i| 
o Склонен обнулять веса менее важных признаков, выполняя отбор 
признаков (feature selection). 
o Создает разреженные модели. 
• L2-регуляризация (Ridge): Loss = Ошибка + α * Σ(w_i)² 
o Уменьшает все веса пропорционально, но редко обнуляет их совсем. 
o Эффективно решает проблему мультиколлинеарности. 
Плюсы: 
1. Снижает переобучение (уменьшает variance). 
2. Улучшает численную устойчивость. 
3. Lasso: помогает интерпретировать модель, отбирая самые важные фичи. 
Минусы: 
1. Вносит смещение (bias) в оценку параметров. 
2. Неправильно подобранный α может привести к недообучению. 