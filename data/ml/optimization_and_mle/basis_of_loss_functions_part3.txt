16. Wasserstein Loss 
Wasserstein Loss — это функция потерь, основанная на Wasserstein-1 
расстоянии (Earth Mover’s Distance), которая измеряет, насколько одна 
вероятность распределения похожа на другую. 
В контексте GAN это расстояние используется для более стабильного обучения 
генератора и дискриминатора (критика). 
Идея: 
• Вместо того чтобы предсказывать вероятность (как в обычных GAN), критик 
возвращает произвольное скалярное значение. 
• Разница средних оценок для реальных и фейковых образцов приближает 
Wasserstein расстояние между распределениями. 
• Чем оно меньше, тем «ближе» сгенерированные данные к реальным. 
Применение: 
• WGAN 
• WGAN-GP (с добавлением градиентного штрафа) 
• Стабильное обучение GAN при сложных данных 
Плюсы: 
• Более стабильное обучение, чем с BCE Loss. 
• Градиенты не исчезают, даже если генератор сильно отстаёт. 
• Лучшая интерпретация значения лосса (можно мониторить качество 
напрямую). 
Минусы: 
• Требует ограничения Липшица (weight clipping или gradient penalty). 
• Немного сложнее реализовать, чем BCE. 
• Не всегда очевидно, как правильно тюнинговать. 
Примечание: 
• В WGAN-GP вместо жёсткого weight clipping используют градиентный 
штраф для соблюдения 1-Lipschitz условия. 
• Если у критика Loss ≈ 0 → распределения почти совпали. 
• В отличие от BCE, тут нет сигмоиды на выходе. 
17. Perceptual Loss 
Perceptual Loss — это функция потерь, которая сравнивает не сырые пиксели, а 
высокоуровневые признаки, извлечённые предобученной нейросетью (обычно 
VGG). 
Идея в том, что два изображения могут иметь разные пиксели, но выглядеть 
одинаково для человека — именно такие отличия Perceptual Loss и игнорирует. 
Идея: 
• Обычный MSE по пикселям наказывает за любые отличия, даже за 
небольшие сдвиги или шум. 
• Perceptual Loss смотрит на разницу в семантике и структуре изображения. 
• Если картинка изменилась так, что человек всё ещё её воспринимает как ту 
же, лосс будет маленьким. 
Применение: 
• Суперразрешение (ESRGAN, SRGAN) 
• Передача стиля (Style Transfer) 
• Генеративные модели (VQ-VAE, Diffusion Models) 
• Реконструкция изображений после сжатия 
• Обучение моделей для апскейла в видео 
Плюсы: 
• Соответствует человеческому восприятию лучше, чем L1/L2 по пикселям. 
• Хорошо работает в задачах, где важна «красота» результата. 
• Можно комбинировать с другими лоссами (например, с L1 и GAN Loss). 
Минусы: 
• Зависит от выбранной предобученной модели (обычно VGG19). 
• Увеличивает время обучения (надо прогонять данные через ещё одну сеть). 
• Иногда сохраняет артефакты, если используется без регуляризации. 
Примечание: 
• Обычно берут 2–3 слоя VGG и усредняют лоссы по ним. 
• Можно комбинировать с Style Loss для передачи текстур. 
• ESRGAN улучшил результат, добавив Relativistic GAN Loss к Perceptual 
Loss. 
18.Triplet loss 
Triplet Loss — это функция потерь, которая учит модель так, чтобы похожие 
объекты в пространстве эмбеддингов находились ближе, а разные — дальше. 
Для этого используются тройки образцов: 
• Anchor — исходный объект 
• Positive — объект того же класса (похожий) 
• Negative — объект другого класса (не похожий) 
Идея: 
• Anchor и Positive должны быть ближе друг к другу, чем Anchor и Negative, 
как минимум на α. 
• Если модель уже выполняет это условие — лосс = 0. 
• Таким образом модель учится «вытягивать» положительные пары и 
«раздвигать» отрицательные. 
Применение: 
• Face recognition (FaceNet, DeepFace) 
• Поиск похожих изображений (image retrieval) 
• Рекомендательные системы (сравнение предпочтений) 
• Speaker verification (определение личности по голосу) 
• Метрика в задачах сравнения текстов (Siamese networks) 
Плюсы: 
• Модель учится работать с относительными расстояниями, а не 
абсолютными классами. 
• Универсальна — можно применять к изображениям, аудио, тексту. 
• Хорошо масштабируется на unseen-классы (few-shot, zero-shot). 
Минусы: 
• Требует продуманного hard negative mining (подбор сложных 
отрицательных примеров). 
• Обучение может быть медленным из-за большого числа комбинаций троек. 
• Чувствительна к выбору margin α. 
Примечание: 
• В FaceNet обычно используют L2-нормализацию эмбеддингов перед 
вычислением расстояний. 
• Hard negative mining — ключевой момент: если negative слишком лёгкий, 
лосс быстро обнуляется, и обучение не идёт. 
• Triplet Loss можно расширить в N-pair Loss и Quadruplet Loss. 
19. KL Divergence Loss 
KL Divergence Loss (Кульбака–Лейблера дивергенция) — это мера того, насколько 
одно распределение вероятностей отличается от другого. 
Используется, когда модель должна не просто выдавать метки, а 
аппроксимировать целое распределение. 
Идея: 
• KL дивергенция = «Сколько лишней информации потребуется, если 
использовать Q вместо P» 
• Если P и Q совпадают — дивергенция = 0. 
• Чем больше расхождение, тем больше штраф. 
Применение: 
• VAE (Variational Autoencoders) — KL loss заставляет латентное 
распределение быть ближе к нормальному N(0,I) 
• Knowledge Distillation — обучение одной модели (студента) на 
предсказаниях другой (учителя) 
• Bayesian Neural Networks — регуляризация весов через аппроксимацию 
постериоров 
• Распознавание речи / NLP — сравнение вероятностных распределений 
слов 
• RL (Policy Gradient) — ограничение изменения политики между итерациями 
(PPO) 
Плюсы: 
• Учитывает всю форму распределения, а не только среднее/моду. 
• Строго математически обоснован в инфотеории. 
• Можно комбинировать с другими лоссами. 
Минусы: 
• Несимметричен: DKL (P∥Q) != DKL (Q∥P) 
• Может «взрываться», если Q(x)→0 при P(x)>0 
• Не всегда интуитивно интерпретируется в сложных моделях 
20.Почему логистическая регрессия использует логарифмическую 
функцию потерь? 
Логистическая регрессия использует логарифмическую функцию потерь (её ещё 
называют log loss или бинарная кросс-энтропия), потому что: 
1. Она хорошо подходит для задачи бинарной классификации, где нужно 
предсказать вероятность принадлежности к классу (значение от 0 до 1). 
2. Логарифмическая функция потерь сильно штрафует за неправильные 
уверенные предсказания. Например, если модель уверена, что объект 
принадлежит к классу 1 (предсказывает вероятность близкую к 1), а на 
самом деле это класс 0, то потери будут очень большими. Это помогает 
быстрее и эффективнее обучать модель. 
3. Она связана с максимизацией правдоподобия (MLE). Минимизируя 
логарифмическую функцию потерь, мы максимизируем вероятность 
правильных меток на данных, что математически обосновано. 
4. Благодаря своей форме функция потерь дифференцируема и удобна для 
градиентного спуска. 