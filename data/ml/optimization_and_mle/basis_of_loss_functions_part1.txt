1. Основы функции потерь 
1. Что такое функция потерь (loss function)? 
Функция потерь — это числовая функция, которая измеряет, насколько 
предсказания модели отклоняются от реальных значений. Она отражает ошибку 
модели на конкретных данных и служит метрикой качества в процессе обучения. 
Минимизация функции потерь через оптимизацию (например, градиентный 
спуск) позволяет улучшать параметры модели. Функция потерь должна быть 
дифференцируемой, чтобы можно было вычислять градиенты для обновления 
весов. Разные задачи требуют разных функций потерь — например, MSE для 
регрессии и кросс-энтропия для классификации. 
2. Чем отличается функция ошибки (error) от функции потерь? 
Функция ошибки — это метрика, которая отражает, насколько модель 
ошибается в предсказаниях, обычно измеряется количеством или долей 
неправильных ответов (например, accuracy error). Она проста и часто 
дискретна, не учитывает степень ошибки, а только факт ошибки. 
Функция потерь — это непрерывная и дифференцируемая функция, 
используемая в обучении модели для оценки качества предсказаний. Она 
измеряет не просто факт ошибки, а величину отклонения предсказания от 
истинного значения, что позволяет применять методы оптимизации, такие 
как градиентный спуск. Функция потерь играет ключевую роль в обновлении 
параметров модели и достижении минимальной ошибки. 
Таким образом, функция ошибки — это больше про оценку итогового качества 
модели, а функция потерь — про механизм обучения и корректировки модели. 
3. Зачем нужна функция потерь при обучении модели? 
Функция потерь — это основная мера качества предсказаний модели, которая 
показывает, насколько предсказания отличаются от истинных значений. Она 
нужна для нескольких целей: 
1. Оценка ошибки: позволяет количественно измерять ошибку модели на 
каждом шаге обучения. 
2. Обратное распространение ошибки: функция потерь должна быть 
дифференцируемой, чтобы можно было вычислить градиенты и понять, в 
каком направлении и с какой силой корректировать параметры модели. 
3. Управление обучением: по значению функции потерь можно судить о 
прогрессе обучения — уменьшается ли ошибка, или модель перестала 
улучшаться. 
4. Оптимизация: обучение модели сводится к минимизации функции потерь 
— поиск параметров, при которых ошибка минимальна. 
5. Оценка на новых данных: функция потерь может использоваться и для 
проверки качества модели на тестовом наборе. 
4. Почему важно, чтобы функция потерь была дифференцируемой? 
Функция потерь должна быть дифференцируемой, потому что обучение модели 
происходит с помощью градиентного спуска — метода, который требует 
вычисления производных (градиентов) по параметрам модели. Если функция 
потерь не дифференцируема в какой-то точке, то градиент не определён, и 
алгоритм не сможет корректно обновлять параметры. Это затруднит или сделает 
невозможным оптимизацию модели. 
5. Что такое MSE (Mean Squared Error) и где он применяется? 
Определение: 
MSE — это среднее значение квадратов разностей между предсказанными 
значениями модели и истинными значениями. Она измеряет среднюю "энергию" 
ошибки, показывая насколько сильно в среднем предсказания отклоняются от 
правильных ответов. 
Формула: 
где: 
• yi  — истинные значения, 
• y^ i  — предсказанные моделью, 
• n — количество наблюдений. 
Особенности: 
• Чувствительность к выбросам: 
MSE очень чувствительна к большим ошибкам, потому что квадрат 
увеличивает влияние больших расхождений. Это хорошо, когда хочется 
особенно "наказывать" большие ошибки, но плохо, если в данных много 
выбросов — они могут сильно исказить результат. 
• Дифференцируемость: 
Функция MSE гладкая и дифференцируемая, что очень важно для 
применения градиентных методов оптимизации — можно легко вычислить 
производные и обновлять параметры модели. 
• Интерпретация в терминах дисперсии: 
MSE можно рассматривать как сумму дисперсии и смещения (в терминах 
ошибки прогноза), что связывает её с теорией оценки качества моделей. 
• Использование: 
Часто используется в задачах регрессии, где надо минимизировать 
среднюю ошибку предсказания. Также применяется для оценки качества 
сгенерированных изображений, где мы сравниваем пиксели с оригиналом. 
Минусы: 
• Из-за сильной чувствительности к выбросам иногда лучше использовать 
альтернативы, например, MAE или Huber Loss. 
• MSE не является интуитивно понятной метрикой, так как квадраты не 
измеряются в тех же единицах, что и исходные данные (например, метры в 
квадрате). 
6. Почему MSE "наказывает" за большие ошибки сильнее? 
MSE (Mean Squared Error) "наказывает" за большие ошибки сильнее, потому что 
при вычислении ошибки каждая разница между предсказанным и реальным 
значением возводится в квадрат. Это означает, что ошибки с большими 
отклонениями увеличиваются экспоненциально, а не линейно, как, например, в 
MAE (Mean Absolute Error). Такой подход заставляет модель уделять больше 
внимания большим ошибкам и стремиться их уменьшить в процессе обучения. 
Однако из-за этого MSE может быть чувствительна к выбросам — единичные 
большие ошибки будут сильно влиять на итоговую метрику и обучение. 
7. Что такое MAE (Mean Absolute Error) и когда он лучше? 
MAE — это среднее абсолютное отклонение между предсказанными значениями 
и реальными. Формула: 
Плюсы MAE: 
• Устойчивость к выбросам: В отличие от MSE, где ошибка возводится в 
квадрат и большие ошибки "наказываются" сильно, MAE равномерно 
взвешивает ошибки, без сильного акцента на большие расхождения. Это 
полезно, если данные содержат шум или выбросы. 
• Интуитивная интерпретация: Поскольку берётся просто абсолютное 
отклонение, MAE легче понять и интерпретировать — это среднее 
расстояние предсказания от истинного значения в тех же единицах 
измерения. 
• Стабильность: Модель, оптимизированная на MAE, будет меньше 
подвержена смещению из-за редких, но крупных ошибок. 
Минусы MAE: 
• Не дифференцируемость в нуле: Абсолютная функция не является 
дифференцируемой в точке 0, что может усложнять вычисление градиентов 
при обучении некоторых моделей (хотя на практике используют 
приближения или субградиенты). 
• Медленнее сходится: Обучение с MAE часто медленнее и менее 
устойчиво, чем с MSE, из-за особенностей градиентного спуска. 
• Игнорирование крупных ошибок: В случаях, когда нужно особенно 
наказывать крупные ошибки (например, в финансовых моделях с большими 
потерями), MAE может быть менее эффективна, так как не выделяет такие 
ошибки по-настоящему. 
Особенности применения: 
• MAE часто выбирают, когда важна стабильность оценки ошибок и когда 
выбросы или шумы в данных могут сильно исказить MSE. 
• В задачах регрессии с реальными измерениями (например, предсказание 
температуры, цены, роста) MAE помогает понять среднюю ошибку в 
понятных единицах. 
• Иногда комбинируется с другими лоссами (например, Huber loss), чтобы 
объединить плюсы MAE и MSE. 
8. Что такое Huber loss? 
Описание: 
Huber loss — это комбинация MAE и MSE, которая ведет себя как MSE для 
маленьких ошибок и как MAE для больших. Благодаря этому она пытается взять 
лучшее из обоих миров: быть устойчивой к выбросам, но при этом гладкой и 
удобной для оптимизации. 
Формально, при пороговом значении δ\deltaδ: 
Плюсы Huber Loss: 
• Устойчивость к выбросам: Для больших ошибок поведение как у MAE — 
лосс растет линейно, а не квадратично, что уменьшает влияние редких 
выбросов. 
• Гладкость и дифференцируемость: В отличие от MAE, Huber loss гладкая 
(дифференцируемая) во всех точках, что облегчает оптимизацию и ускоряет 
обучение. 
• Баланс между чувствительностью и устойчивостью: При малых ошибках 
ведет себя как MSE, что хорошо для точного подстраивания, при больших — 
как MAE, снижая влияние аномалий. 
• Гибкость: Порог δ\deltaδ можно настраивать, меняя степень 
чувствительности к ошибкам. 
Минусы Huber Loss: 
• Нужно выбирать параметр δ\deltaδ: Если δ\deltaδ слишком мал — 
поведение будет похоже на MAE, если слишком велик — на MSE. Подбор 
оптимального δ\deltaδ иногда требует экспериментов. 
• Сложнее вычислять: Чем MAE и MSE, чуть более сложная формула и 
вычисления, хотя на практике это почти не заметно. 
• Может быть менее интуитивной: По сравнению с чистым MAE и MSE, 
требует понимания, зачем именно нужна эта смесь. 
Особенности применения: 
• Особенно полезна, когда данные содержат умеренное количество 
выбросов, но при этом важна точность на основной массе данных. 
• Широко используется в регрессиях, включая обучение нейронных сетей. 
• Может служить более универсальной заменой MSE и MAE, если сложно 
заранее понять, какая функция лосса лучше. 
• Применяется в задачах с измерениями в реальных величинах, где важна 
стабильность и одновременно чувствительность. 
Итог: 
Huber loss — это компромисс между MSE и MAE, который помогает эффективно 
обучать модели в реальных условиях с шумными данными, снижая влияние 
выбросов и сохраняя гладкость функции потерь для оптимизации. 