2. Градиентный спуск 
11.Что такое градиент функции? 
Градиент функции — это вектор, состоящий из частных производных функции по 
всем её аргументам, который указывает направление наибыстрейшего роста 
функции в данной точке. 
Смысл: 
• Модуль (длина) градиента показывает, насколько быстро функция растёт в 
этом направлении. 
• Направление градиента — в сторону наибольшего возрастания функции. 
• В машинном обучении для минимизации функции потерь мы движемся в 
сторону антиградиента (противоположного вектора), чтобы как можно 
быстрее уменьшать значение функции. 
12.Как работает базовый градиентный спуск? 
Базовый градиентный спуск (Gradient Descent) — это метод оптимизации, 
который ищет минимум функции потерь, двигаясь в направлении антиградиента. 
Связь с backpropagation 
В нейросетях градиентный спуск работает в связке с алгоритмом обратного 
распространения ошибки: 
• backpropagation вычисляет градиенты для всех весов через правило 
цепочки. 
• gradient descent обновляет веса на основе этих градиентов. 
�
� Варианты (не базовые) градиентного спуска 
1. Batch Gradient Descent 
a. Использует весь датасет для вычисления градиента. 
b. Плюсы: точное направление. 
c. Минусы: медленно при больших данных. 
2. Stochastic Gradient Descent (SGD) 
a. Обновление весов после каждого примера. 
b. Плюсы: быстрые шаги, лучше вылезает из локальных минимумов. 
c. Минусы: шумная траектория. 
3. Mini-Batch Gradient Descent 
a. Обновления на небольших подвыборках (батчах) данных. 
b. Плюсы: компромисс между скоростью и стабильностью. 
4. Momentum 
a. Добавляет “инерцию” в обновление, чтобы сглаживать шум и 
ускорять движение в нужном направлении. 
5. Nesterov Accelerated Gradient (NAG) 
a. Более “предсмотрительный” вариант Momentum, смотрит вперёд 
перед корректировкой. 
6. Adagrad, RMSprop, Adam 
a. Адаптивная подстройка шага обучения для каждого параметра. 
✅ Плюсы: 
• Простота реализации. 
• Подходит для любых дифференцируемых функций. 
• Легко комбинировать с адаптивными методами. 
❌ Минусы: 
• Чувствительность к выбору learning rate. 
• Может застрять в локальных минимумах или седловых точках. 
• Неэффективен для очень сложных ландшафтов без модификаций. 
13.Что такое learning rate (шаг обучения)? 
Learning rate (η) — это коэффициент, определяющий, насколько сильно мы 
изменяем параметры модели в направлении антиградиента на каждом шаге 
обучения. 
Влияние величины η 
• Слишком большой → шаги перескакивают минимум, траектория 
колеблется, обучение может не сойтись. 
• Слишком маленький → очень медленное обучение, модель может 
“застрять” в седловой точке или на плато, но не потому что увеличивается 
шанс попасть в локальный минимум, а потому что выхода из него можно 
ждать бесконечно долго. 
• Оптимальный → баланс между скоростью сходимости и стабильностью. 
�
� Динамический learning rate 
Вместо фиксированного шага обучения используют: 
• Decay (уменьшение) — шаг уменьшается по мере обучения. 
• Adaptive методы — Adagrad, RMSprop, Adam и др., подбирают шаг для 
каждого параметра отдельно. 
• Learning rate schedulers — изменяют η по заданному расписанию 
(ступенчато, экспоненциально, косинусно и т.д.). 
Пример: 
Если η=0.1 и градиент равен 5, то изменение веса = 0.1⋅5=0.5.Слишком большой η 
мог бы, например, перескочить минимум с -1 прямо на +3 вместо плавного 
приближения. 
14.Почему слишком большой learning rate — плохо? 
Слишком большой learning rate (η) приводит к тому, что шаги обновления 
параметров становятся слишком большими относительно формы функции 
потерь. 
�
� Что происходит: 
• Вместо того чтобы постепенно приближаться к минимуму, параметры 
перескакивают через него. 
• Траектория обновлений становится нестабильной: модель может 
колебаться вокруг минимума или уходить в область с ещё большей 
ошибкой. 
• Градиенты могут расти (“exploding gradients”), особенно в глубоких 
нейросетях, что приведёт к числовой нестабильности (NaN в весах/лоссе). 
�
� Признаки на практике: 
• График лосса: вместо плавного убывания — сильные колебания или рост. 
• Метрики качества: прыгают туда-сюда, не стабилизируются. 
• Градиенты: становятся аномально большими. 
Пример: 
Представь, что минимум находится в точке x=0. Если η слишком большой, при 
шаге из x=−1 мы можем попасть в x=3, а не в x=−0.5. Модель так и будет “метаться” 
вокруг цели. 
15.Почему слишком маленький learning rate — тоже плохо? 
Слишком маленький learning rate (η) приводит к тому, что обновления весов 
становятся очень маленькими, из-за чего: 
• Обучение идёт очень медленно, требуется много итераций, чтобы увидеть 
заметный прогресс. 
• Модель может «застрять» на плато — участке функции потерь, где 
градиенты близки к нулю и изменения параметров минимальны. 
• Практически — обучение превращается в длительный, неэффективный 
процесс с риском не дойти до глобального минимума за разумное время. 
Визуализация 
Пусть функция потерь имеет участок почти горизонтальный (плато). Если шаги 
маленькие, модель будет “ползти” по нему очень медленно. 
Итог 
• Выбирать learning rate нужно так, чтобы шаги были достаточно большими 
для заметного уменьшения loss, но не слишком большими, чтобы не 
пропускать минимум. 
• Поэтому применяют адаптивные методы и scheduler’ы. 
16.Как определить, что модель застряла в локальном минимуме? 
• Лосс не снижается или колеблется в пределах небольшой амплитуды — 
индикатор того, что обучение застопорилось. 
• Градиенты становятся очень малыми (приближаются к нулю) — значит 
параметры модели почти не меняются. 
• Можно наблюдать плато или очень медленное улучшение метрик. 
• Визуализация графика loss — часто показывает "флэт" участок. 
«Флэт» — это плоский участок на графике функции ошибки (лосса), где значение 
почти не меняется и градиенты близки к нулю. То есть обучение «замирает» и 
делает очень маленькие шаги. 
• При застревании в локальном минимуме улучшения могут не появляться, 
даже если global minimum находится дальше. 
Дополнительно: 
• Локальный минимум — точка, где градиент равен нулю, но она не 
обязательно глобально лучшая. 
• Можно проверить, меняя начальные веса, использовать разные 
оптимизаторы или методы сходимости. 
17.Что происходит на плато функции ошибки? 
Плато функции ошибки — это участок на поверхности функции потерь, где: 
• Значение ошибки меняется очень слабо (почти стабильно). 
• Градиенты становятся очень малыми (почти нулевыми). 
• Обучение замедляется или приостанавливается — модель делает очень 
маленькие обновления весов. 
Почему это проблема? 
• Модель может «застрять» на плато, так как градиенты не дают явного 
направления для движения. 
• Это замедляет сходимость и может привести к длительной тренировке без 
улучшений. 
Как с этим бороться? 
• Изменение learning rate (например, увеличить, чтобы «перепрыгнуть» 
плато). 
• Использование методов оптимизации с импульсом (Momentum, Adam). 
• Перезапуск обучения с разными инициализациями. 
18.Что такое сходимость алгоритма градиентного спуска? 
Сходимость — это процесс, когда алгоритм обучения (градиентный спуск) 
постепенно приближается к минимуму функции потерь. 
Характеристики сходимости: 
• Значения loss уменьшаются с каждым шагом или эпохой. 
• Градиенты уменьшаются, приближаясь к нулю. 
• Обновления весов становятся всё менее заметными. 
• На графике лосса наблюдается плавный тренд вниз без резких колебаний. 
Когда сходимость считается достигнутой? 
• Когда лосс стабилизируется или уменьшается очень медленно. 
• Когда градиенты становятся очень малыми. 
• Когда выполнение дополнительных итераций не улучшает результат. 
19.Какие есть способы регулировать скорость сходимости? 
1. Изменение learning rate (lr) 
a. Ручное изменение шага обучения — уменьшение или увеличение по 
необходимости. 
2. Learning rate schedulers 
a. Автоматическое изменение lr во время обучения по расписанию 
(например, экспоненциальное снижение, ступенчатое, цикличное). 
3. Инициализация весов 
a. Хорошая инициализация (Xavier, He) помогает модели быстрее 
сходиться, избегая проблем с градиентами. 
4. Использование разных оптимизаторов 
a. Adam, RMSprop, SGD с Momentum и другие — разные методы 
обновления весов влияют на скорость сходимости. 
5. Правильный подбор и настройка данных 
a. Качественные данные, аугментации в компьютерном зрении и т.п. 
помогают обучению идти стабильнее и быстрее. 
20.В чём разница между глобальным и локальным минимумом? 
• Глобальный минимум — это точка на поверхности функции потерь, где 
значение функции самое минимальное во всём пространстве параметров. 
• Локальный минимум — это точка, где функция меньше, чем в соседних 
точках, но не обязательно самая низкая в целом. 
Как это понять визуально: 
• Глобальный минимум — самая глубокая «ямка» на всей «поверхности» 
функции потерь. 
• Локальные минимумы — мелкие впадины, которые могут «заставить» 
алгоритм остановиться, хотя существует точка с ещё меньшим значением 
функции. 
Почему важно: 
• В локальном минимуме модель может «застрять» и не найти оптимальное 
решение. 
• В современных глубоких сетях локальные минимумы обычно не так 
страшны, как раньше думали, и зачастую они достаточно хороши.