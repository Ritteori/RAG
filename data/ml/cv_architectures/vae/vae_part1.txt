7. VAE 
1. Мотивация перехода от AE к VAE 
Проблема в том, что у AE нет контроля над латентным 
пространством. 
• z — это просто точка, полученная детерминированно из x. 
• Никакого распределения по z не задаётся. 
• Поэтому если взять “случайный” z, он может не соответствовать 
никакому реальному объекту — декодер не умеет работать с ним. 
Иными словами, AE не генеративная модель — он просто сжимает и 
восстанавливает данные, но не умеет моделировать распределение, 
из которого они пришли. 
VAE решает это так: 
• Он задаёт вероятностное приближение к распределению 
скрытых переменных q(z∣x). 
• Обучается не просто восстанавливать x, а максимизировать 
правдоподобие данных через приближение к истинному 
распределению p(x). 
• Благодаря этому можно сэмплировать новые z из prior 
p(z)∼N(0,1) и получать реалистичные новые примеры через 
декодер. 
Интуитивно: 
AE просто учится "запомнить" способ восстановления каждого входа. 
VAE учится "понять", какое распределение порождает эти входы, и 
научиться создавать из него новые. 
2. Архитектура VAE (encoder, decoder, latent space) 
VAE по структуре очень похож на обычный Autoencoder, 
но с ключевым отличием — стохастическим латентным 
представлением. 
1
️
⃣ Encoder 
Задача энкодера — получить параметры распределения латентной 
переменной z, 
а не конкретное значение, как в обычном AE. 
Если вход x — изображение (например, 1×28×28 для MNIST), 
энкодер — это обычно CNN, которая выдаёт два вектора: 
Каждый элемент этих векторов описывает нормальное распределение 
по координате zi : 
2
️
⃣ Latent Space 
Это “скрытое пространство” размерности d (например, 16, 32, 128). 
Но теперь z — случайная величина, а не фиксированный код, как в 
AE. 
Чтобы обучать модель через backpropagation, используется 
reparameterization trick: 
где ⊙ — поэлементное умножение. 
Идея: вместо того чтобы сэмплировать z напрямую, 
мы берём детерминированное μ,σ и добавляем шум ε — 
это позволяет провести градиент обратно через encoder. 
3
️
⃣ Decoder 
Декодер принимает сэмплированный z и восстанавливает исходные 
данные x^=fdec(z). 
Если вход — изображение, decoder обычно построен зеркально 
encoder-у: 
• ConvTranspose2d вместо Conv2d, 
• BatchNorm и ReLU/LeakyReLU, 
• на выходе — сигмоида для нормализации [0,1]. 
4
️
⃣ Общая схема 
(Примерная структура — Encoder → Sampling → Decoder) 
Интуитивно 
• Encoder описывает “где в латентном пространстве лежит объект 
и насколько мы в этом уверены”. 
• Decoder генерирует пример из этой области, добавляя 
стохастику. 
• Благодаря этому можно интерполировать между точками z и 
получать плавные переходы между объектами. 
3. Что представляют собой μ и σ в encoder 
В encoder VAE на выходе получаются два вектора — μ и σ (или logσ²), 
которые описывают параметры нормального распределения 
q(z∣x)=N(μ,σ2) для латентной переменной z. 
То есть encoder не выдаёт один “код”, а учится приближать 
распределение скрытого представления объекта. 
• μ (mean) — показывает “центр” латентного распределения (где 
примерно находится образец). 
• σ (std) — показывает “неуверенность” модели, насколько 
широко оно размыто. 
Таким образом, модель оценивает не только, где лежит объект в 
латентном пространстве, но и насколько она уверена в этом 
положении. 
�
� Простыми словами (для себя): 
• μ и σ — это не распределение “по пикселям”, а по латентным 
признакам, которые модель выделила. 
• Каждый элемент вектора z (например, 32 признака) имеет своё μᵢ 
и σᵢ — 
как будто мы говорим: 
“по этому направлению в латентном пространстве данные 
обычно около 0.7, но с разбросом 0.2”. 
• Вся совокупность этих направлений образует многомерное 
нормальное распределение. 
4. Reparameterization trick и зачем он нужен 
Reparameterization trick нужен, чтобы сделать процесс 
сэмплирования z дифференцируемым, 
и чтобы можно было проводить градиенты обратно через encoder. 
Мы не можем просто взять два вектора μ и σ и подать их напрямую в 
decoder, 
потому что decoder ожидает один конкретный латентный вектор z, 
сэмплированный из распределения N(μ,σ2). 
Если бы мы сэмплировали z напрямую (через torch.randn внутри 
сети), 
операция была бы недифференцируема, 
и encoder не смог бы обновляться градиентами. 
Поэтому мы “разделяем” стохастику и детерминизм: 
z=μ+σ⊙ε, где ε∼N(0,I)  
Теперь μ и σ — детерминированные (через encoder), 
а случайность идёт только через ε, который не мешает backprop-у. 
�
� Интуитивно (если объяснить своими словами): 
• Encoder учится предсказывать не просто вектор признаков, а 
параметры распределения. 
• Чтобы сэмплировать z, нужно добавить шум (иначе модель не 
будет стохастической). 
• Но обычное сэмплирование “обрывает” вычислительный граф — 
PyTorch не сможет вычислить ∂Loss/∂μ, ∂Loss/∂σ. 
• Reparameterization trick “обходит” это — 
делает z функцией от μ, σ и ε, 
где ε — источник случайности, а μ, σ — обучаемые параметры. 
�
� Почему нельзя просто подать μ и σ в decoder: 
1. Decoder не знает, как интерпретировать “два входа”. 
Ему нужно один латентный вектор, а не параметры 
распределения. 
2. Если бы decoder брал μ и σ напрямую, 
модель перестала бы быть вероятностной: 
она бы всегда декодировала среднее распределения, 
теряя вариативность и способность к генерации. 
3. А sampling без трюка — недифференцируем, 
значит encoder не обучается. 

5. Что такое latent variable z и как он используется 
Latent variable (скрытая переменная) — это вектор, который 
описывает сжатое, абстрактное представление данных. 
В случае VAE — это кодированная суть картинки, звука, текста и т.д. 
Он не наблюдается напрямую, но содержит всю нужную 
информацию для восстановления исходных данных. 
�
� Как появляется z в VAE 
Encoder принимает входное изображение x 
и возвращает два вектора: 
μ(x), σ(x)  
Они задают распределение: 
q(z∣x)=N(μ(x),σ2(x))  
После этого мы сэмплируем z через reparameterization trick: 
z=μ+σ⊙ε,ε∼N(0,I)  
�
� Как используется z 
1. Передаётся в decoder 
Decoder получает z и пытается восстановить исходный объект: 
x^=p(x∣z)  
То есть он учится “разворачивать” сжатое представление обратно в 
картинку. 
2. Для генерации новых данных 
После обучения можно просто сэмплировать: 
z∼N(0,I)  
и подать в decoder — он создаст новое, похожее, но не идентичное 
изображение. 
3. Для анализа структуры данных 
Латентное пространство z — это “карта” обученных признаков. 
Там близкие объекты (по смыслу) оказываются рядом, 
а разные — далеко. 
Поэтому по z можно делать кластеризацию, интерполяцию и 
даже арифметику смыслов. 