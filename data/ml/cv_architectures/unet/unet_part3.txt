8. Особенности обучения и выбор функции потерь 
1
️
⃣ Основная цель обучения 
U-Net обучается решать задачу сегментации, то есть предсказывать 
пиксельную маску для каждого объекта/класса. 
• В отличие от классификации, где один логит = один класс на 
изображение, здесь каждый пиксель — отдельный 
предсказательный элемент. 
• Цель — минимизировать расхождение предсказанной маски и 
ground-truth маски. 
3
️
⃣ Особенности обучения 
1. Баланс классов: 
a. Для мед. сегментации или tiny objects нужно корректировать loss 
(pos_weight или Dice), иначе сеть будет предсказывать почти всё 
background. 
2. Аугментации: 
a. Геометрические (flip, rotate, scale), 
b. Цветовые (brightness, contrast), 
c. Elastic deformation (очень популярно в U-Net для мед. данных). 
→ Улучшают обобщение, компенсируют малый датасет. 
3. Обучение на разных масштабах (deep supervision): 
a. Иногда подключают loss на промежуточных уровнях decoder → 
быстрее сходится. 
4. Регуляризация: 
a. Dropout в bottleneck или decoder, чтобы не переобучаться на мелких 
объектах. 
4
️
⃣ Отличие от детектора 
• U-Net — пиксельная сегментация: каждый пиксель получает логит. 
• YOLO / Faster R-CNN — детекция объектов: предсказывают bounding box + 
класс для каждого объекта. 
• Если попытаться «сделать маску прямоугольника» для детекции: 
o Не получится локализовать объекты с разной позицией/размерами 
надёжно, 
o Потеряется логика NMS, anchor-box, confidence score, 
o Маска не даёт прямого способа разделить несколько объектов, 
которые пересекаются. 
✅ TL;DR 
• Loss: BCE, Weighted BCE, Dice, BCE+Dice — основной выбор для 
сегментации. 
• Особенности обучения: баланс классов, аугментации, deep supervision, 
регуляризация. 
• Почему не детектор: U-Net работает на пиксельном уровне, не учитывает 
bounding box, confidence и NMS, поэтому не заменяет YOLO или Faster R
CNN для детекции. 
9. Модификации и развитие U-Net (U-Net++, Attention U-Net, 3D и 
др.) 
1
️
⃣ U-Net++ (Nested U-Net) 
Что это: 
• Расширение стандартного U-Net с дополнительными skip 
connections между уровнями энкодера и декодера, не только на 
одном слое, а через несколько промежуточных уровней. 
• Иногда называют nested skip connections. 
Зачем: 
• Стандартный skip соединяет encoder и decoder напрямую → 
semantic gap между ними большой (фичи на разных уровнях 
абстракции). 
• U-Net++ добавляет промежуточные блоки, которые сглаживают 
semantic gap, чтобы decoder лучше понимал, как интегрировать 
локальные и глобальные признаки 
Semantic gap и нормализация: 
Перед конкатенацией skip connections часто используют 1×1 
свёртку и BatchNorm/LayerNorm, чтобы привести количество 
каналов и масштабы признаков encoder и decoder к 
сопоставимым значениям. 
Зачем: уменьшает semantic gap между feature maps разного 
уровня абстракции, облегчает обучение декодера и повышает 
стабильность градиентов.. 
Особенности: 
• Каждая ветка decoder получает несколько feature maps из 
encoder на разных глубинах. 
• Улучшает точность сегментации, особенно при сложных 
объектах. 
• Но увеличивает количество параметров и память, поэтому 
может быть медленнее. 
2
️
⃣ Attention U-Net 
Что это: 
• Добавляет attention-gates на skip connections. 
• Модель учится выбирать, какие локальные признаки из 
encoder действительно полезны для decoder. 
Зачем: 
• Не все фичи encoder полезны на конкретном уровне decoder → 
без внимания шумные или лишние признаки могут ухудшить 
сегментацию. 
• Attention автоматически подавляет нерелевантные признаки. 
Как работает: 
• На вход skip-connection подается feature map из encoder + 
сигнал из decoder (coarse контекст). 
• Attention-механизм вычисляет маску (0–1) по каналам/пикселям, 
которая взвешивает признаки перед конкатенацией. 
Эффект: 
• Улучшение точности, особенно на маленьких объектах и при 
сильном шуме. 
• Более селективное использование информации из encoder. 
3
️
⃣ 3D U-Net 
Что это: 
• Применение U-Net к 3D данным (например, медицинские 
КТ/МРТ томограммы). 
• Conv2d → Conv3d, MaxPool2d → MaxPool3d, 
Upsample/TransposeConv аналогично. 
Особенности: 
• Feature map: (C, D, H, W) вместо (C, H, W) 
• Позволяет сегментировать объёмы целиком, учитывая 
пространственные взаимосвязи между слоями (например, орган 
в 3D). 
Плюсы: 
• Учитывает контекст по всем трём измерениям, а не только на 
срезах. 
Минусы: 
• Очень высокая нагрузка на GPU (память), 
• Требует уменьшенного batch size или подрезки слайсов/patches. 
4
️
⃣ Residual U-Net / Dense U-Net 
Что это: 
• Внутри каждого ConvBlock добавляются residual connections 
(как в ResNet) или dense connections (как в DenseNet). 
Зачем: 
• Упрощает обучение очень глубоких U-Net, 
• Улучшает градиентный поток, 
• Иногда повышает точность на сложных задачах сегментации. 
5
️
⃣ Variants for Lightweight / Mobile Use 
• Mobile U-Net / Efficient U-Net: 
o Используют depthwise separable conv вместо обычных 
conv, 
o Подходит для сегментации на мобильных устройствах, 
видео в реальном времени. 
• U-Net с уменьшенным количеством каналов: 
o Для маленьких датасетов или задач с ограниченной 
памятью, 
o Быстрее, но чуть хуже точность на сложных объектах. 
6
️
⃣ Другие интересные улучшения 
• Attention + Residual: комбинируют оба подхода → стабильные 
градиенты + селективная интеграция признаков. 
• U-Net с deep supervision: промежуточные лоссы на нескольких 
уровнях decoder → ускоряет обучение и повышает точность. 
• Cascaded U-Net: несколько U-Net подряд → сначала coarse 
сегментация, потом refinement. 
• U-Net для многоклассовой сегментации: multi-head output → 
сегментирует несколько объектов одновременно. 
�
� Итог 
Модификация 
U-Net++ 
Attention U-Net 
3D U-Net 
Residual/Dense 
U-Net 
Lightweight / 
Mobile 
Deep 
Supervision / 
Cascaded 
Цель 
Особенности 
Сгладить semantic gap Nested skip 
connections 
Селективное 
использование 
признаков 
Работа с объёмными 
данными 
Стабильные 
градиенты 
Быстрая сегментация 
Ускорить обучение и 
refinement 
Attention gates на 
skip 
Conv3d, 
MaxPool3d 
Residual / Dense 
внутри блоков 
Depthwise 
separable conv 
Лоссы на 
нескольких 
уровнях 
Минусы 
Больше памяти 
и параметров 
Увеличение 
вычислений 
Очень много 
памяти 
Сложнее 
архитектура 
Потеря точности 