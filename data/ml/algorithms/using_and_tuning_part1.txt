5. Применение и тюнинг 
41.Что такое гиперпараметры модели? 
Гиперпараметры — это параметры, которые задаются пользователем до 
обучения и управляют процессом обучения модели. Они не обучаются из данных 
(в отличие от весов в нейросети или коэффициентов в линейной регрессии). 
Примеры гиперпараметров: 
• k-means: число кластеров kkk. 
• kNN: число соседей kkk. 
• Деревья решений: глубина дерева (max_depth), минимальное число 
объектов в листе (min_samples_leaf). 
• Линейные модели: коэффициенты регуляризации λ\lambdaλ (например, 
параметр C в логистической регрессии). 
• Градиентный бустинг: learning rate, количество деревьев, глубина 
деревьев. 
• Нейросети: размер батча, скорость обучения (learning rate), количество 
эпох, архитектурные параметры (число слоёв, размер скрытых слоёв, patch 
size в ViT). 
Почему они важны: 
• От выбора гиперпараметров напрямую зависит качество модели. 
• Неправильные значения могут привести к переобучению (слишком 
сложная модель) или недообучению (слишком простая). 
• Их подбирают с помощью специальных методов: Grid Search, Random 
Search, Bayesian Optimization и др. 
Итог: 
Гиперпараметры — это «настройки обучения», которые мы задаём извне. Они 
определяют, как именно модель будет учиться, но сами не обновляются в 
процессе обучения. 
42.Как проводится поиск по сетке (Grid Search)? 
Grid Search (поиск по сетке) — это метод подбора гиперпараметров модели 
машинного обучения, при котором мы перебираем все возможные комбинации 
параметров из заранее заданной сетки значений. 
Идея простая: 
• У модели есть гиперпараметры (например, глубина дерева, количество 
соседей в kNN, learning_rate в бустинге и т.д.). 
• Мы выбираем набор значений для каждого гиперпараметра. 
• Алгоритм перебирает все возможные комбинации этих значений и 
оценивает модель (обычно с помощью кросс-валидации) для каждой 
комбинации. 
• Лучшая комбинация — та, которая дала максимальный скор (или 
минимальную ошибку). 
Как это работает внутри 
1. Допустим у тебя 2 гиперпараметра: 
a. max_depth = [2, 3, 5] 
b. min_samples_split = [2, 5] 
Всего комбинаций = 3 × 2 = 6. 
2. Для каждой комбинации модель обучается на k-1 фолдах и проверяется на 
оставшемся (k-fold cross-validation). 
3. Считается средний скор по всем фолдам. 
4. В конце выбирается комбинация, которая даёт наилучший результат. 
Плюсы 
• Очень простой метод. 
• Гарантирует нахождение оптимума внутри заданной сетки. 
Минусы 
• Комбинаторный взрыв: если параметров много, а у каждого длинный 
список значений → число комбинаций растёт экспоненциально. 
• Долго работает на больших моделях/датасетах. 
Оптимизация 
Чтобы уменьшить время: 
• Задавать разумный диапазон параметров (range(1, 10, 2) вместо 
range(1, 10)). 
• Использовать RandomizedSearchCV — случайный перебор (пробует не все 
комбинации, а случайную выборку). 
• Подключать Bayesian Optimization или Optuna — умный поиск по 
параметрам. 
1. Bayesian Optimization (Баесовская оптимизация) 
Идея: 
• Вместо того, чтобы перебрать все комбинации, мы строим 
пробабилистическую модель функции качества (скор) от 
гиперпараметров. 
• Обычно берут Gaussian Process (GP), который аппроксимирует 
«поверхность» ошибки/метрики. 
• Каждый раз, когда мы пробуем новые параметры, мы обновляем модель GP 
и решаем, куда «выгоднее» пойти дальше: 
o попробовать область, где ещё мало точек (exploration) 
o или улучшить область, где уже были хорошие значения 
(exploitation). 
Таким образом, поиск параметров идёт не хаотично, а «умно», шаг за шагом сужая 
область. 
2. Optuna 
Optuna — современный фреймворк для автоматического подбора 
гиперпараметров. 
Он включает несколько стратегий (в т.ч. Байесовскую оптимизацию), но 
отличается удобством. 
Особенности: 
• Define-by-run — параметры задаются прямо в коде (гибко, не как сетка в 
sklearn). 
• Использует Tree-structured Parzen Estimator (TPE) — байесовский подход, 
но более эффективный, чем Gaussian Process. 
• Есть встроенные методы для pruning — остановки неудачных 
экспериментов раньше времени (если видно, что trial идёт плохо). 
• Умеет работать распределённо (можно запускать на нескольких 
GPU/машинах). 
43.Что такое случайный поиск (Random Search)? 
Random Search — это метод подбора гиперпараметров, при котором мы 
выбираем случайные комбинации значений параметров из заданных диапазонов. 
В отличие от Grid Search, который перебирает все комбинации, Random Search 
работает быстрее и часто эффективнее. 
Пример: 
• Пусть есть 3 гиперпараметра: 
o depth = [3, 5, 7, 9] 
o min_samples_leaf = [1, 5, 10, 20] 
o learning_rate = [0.01, 0.05, 0.1, 0.2] 
Grid Search проверит 4×4×4 = 64 комбинации. 
Random Search можно настроить на проверку, например, 20 случайных 
комбинаций, что экономит ресурсы. 
Подковырки: 
• Random Search может не найти глобально лучший набор параметров, но 
часто находит достаточно хороший. 
• Работает лучше, когда у нас есть "широкие" гиперпараметры (например, 
learning rate от 1e-5 до 1). 
• В отличие от Grid Search, хорошо масштабируется на большие 
пространства параметров. 
Современный подход: 
На практике Random Search часто используют как первый шаг, а потом 
подключают Bayesian Optimization / Optuna для более точной донастройки. 
44.Что такое кросс-валидация в контексте настройки 
гиперпараметров? 
Кросс-валидация (Cross-Validation) — это метод оценки качества модели, при 
котором датасет разбивается на несколько частей (folds), и 
обучение/тестирование происходит многократно с разными разбиениями. 
Принцип работы: 
• Делим данные на k частей (например, k=5 → 5-fold CV). 
• На каждом шаге: 
o модель обучается на k-1 фолдах, 
o тестируется на оставшемся 1 фолде. 
• В конце усредняем качество по всем k фолдам. 
Зачем это нужно: 
• Уменьшает риск случайного "удачного" или "неудачного" разбиения. 
• Использует весь датасет максимально эффективно: каждая точка 
побывает и в обучающей, и в тестовой выборке. 
• Дает более устойчивую оценку при подборе гиперпараметров (например, в 
GridSearchCV и RandomizedSearchCV). 
Подковырки, которые стоит знать: 
1. Стратифицированная кросс-валидация 
a. Для задач классификации с дисбалансом классов используют 
StratifiedKFold, чтобы в каждом фолде сохранялись пропорции 
классов. 
2. Время — враг CV 
a. Кросс-валидация дорогая по вычислениям: если 5 фолдов + 100 
комбинаций параметров → модель обучится 500 раз. 
b. Поэтому на больших моделях часто используют меньшее количество 
фолдов (например, 3). 
3. TimeSeriesSplit 
a. Для временных рядов обычная CV не подходит, так как нельзя 
мешать данные во времени. Там используют особую версию, где 
фолды формируются с сохранением временного порядка. 