49.Как выбрать признаки для модели? 
1. Почему важен выбор признаков 
• Слишком много признаков → модель становится шумной, дольше 
обучается, может переобучиться. 
• Лишние признаки → не несут информации, а иногда и ухудшают точность 
(например, шум, коллинеарность). 
• Правильный выбор признаков → улучшает качество, ускоряет обучение, 
повышает интерпретируемость. 
2. Методы выбора признаков 
�
� A. Ручной отбор (Domain knowledge) 
• Инженер или эксперт в предметной области решает, что важно. 
Пример: при кредитном скоринге «возраст» и «доход» очевидно полезны, а 
«любимый цвет» — вряд ли. 
�
� B. Статистические методы 
• Корреляция с таргетом: убираем признаки, которые слабо связаны с 
целевой переменной. 
• Мультиколлинеарность: если два признака сильно коррелируют друг с 
другом, можно оставить только один. 
• Критерии значимости (χ²-тест, ANOVA, взаимная информация). 
�
� C. Методы встроенные в модели (Embedded) 
• Многие алгоритмы сами дают feature importance: 
o Деревья решений, Random Forest, Gradient Boosting → показывают 
вклад признаков. 
o Линейные модели с L1-регуляризацией (Lasso) → зануляют веса 
ненужных признаков. 
• Такие методы сразу учитывают модель + таргет. 
�
� D. Автоматические методы отбора (Feature Selection) 
1. Filter methods — оцениваем признаки независимо от модели (корреляция, 
χ²). 
2. Wrapper methods — тестируем разные подмножества признаков: 
a. Forward selection — начинаем с пустого набора, добавляем признаки 
по одному. 
b. Backward elimination — начинаем со всех, удаляем по одному. 
c. Recursive Feature Elimination (RFE) — обучаем модель, убираем 
наименее важные признаки, повторяем. 
3. Embedded methods — учитывают модель и регуляризацию (Lasso, 
деревья). 
�
� E. PCA и другие методы уменьшения размерности 
• Если признаков очень много и они коррелированы → можно сжать их до 
нескольких главных компонент. 
• Это feature extraction, а не отбор, но решает ту же задачу (уменьшение 
числа входов). 
3. Практические советы 
• Начинай с доменных знаний: экспертиза лучше любого алгоритма. 
• Убирай мусорные признаки (например, ID, timestamp без 
преобразования). 
• Проверяй мультиколлинеарность (VIF, корреляции). 
• Используй регуляризацию (L1 для отбора признаков). 
• Для больших задач → RFE или модели с feature importance. 
• Для интерпретируемости лучше вручную отбирать признаки, чем 
использовать PCA (так как PCA делает абстрактные комбинации). 
50.Как визуализировать результаты модели 
1. Визуализация для классификации 
• Confusion matrix (матрица ошибок) — показывает, какие классы чаще 
всего путаются. 
• ROC-кривая и AUC — анализ качества бинарных классификаторов. 
• PR-кривая — особенно при дисбалансе классов. 
• Bar chart feature importance — важность признаков (для деревьев, 
бустинга). 
• t-SNE / UMAP — визуализация эмбеддингов и того, как классы разделяются 
в пространстве. 
2. Визуализация для регрессии 
• Scatter plot (y_true vs y_pred) — насколько близко предсказания к 
идеальной линии. 
• Residual plots (ошибки = y_true – y_pred) — проверка систематических 
ошибок. 
• Гистограммы ошибок — распределение отклонений. 
• Learning curves — динамика ошибки на train/test при увеличении выборки 
или эпох. 
3. Визуализация в CV 
• Классификация картинок: вывести изображение + предсказанный класс + 
вероятности. 
• Object detection: картинка с боксами + вероятности классов. 
• Segmentation: наложить предсказанную маску на изображение. 
• Heatmaps (Grad-CAM) — показать, какие области повлияли на решение 
модели. 
4. Визуализация в NLP 
• Highlighting tokens — подсветка слов, на которые модель обратила 
внимание. 
• Attention maps (в трансформерах) — показать, какие токены связаны. 
• Word embeddings (t-SNE/UMAP) — проекция слов/предложений в 2D. 
• Confusion matrix по классам (например, для sentiment analysis). 
5. Универсальные методы 
• Learning curves — train vs validation loss. 
• Feature importance / SHAP values — интерпретируемость для любых 
табличных моделей. 
• Partial Dependence Plots (PDP) — влияние отдельных признаков. 
• SHAP / LIME — объяснение отдельных предсказаний. 
Подковырка: 
• «Просто выводить предсказание» — почти бесполезно. Важнее 
анализировать ошибки и интерпретировать, почему модель так решила. 
• В реальных проектах часто используют dashboards (например, через Dash, 
Streamlit, Gradio), где визуализация объединена с интерактивным 
анализом. 
Итог: 
Визуализация результатов модели — это не только показать предсказания, но и 
оценить ошибки, сравнить с таргетом, понять важность признаков, а в CV и 
NLP — наглядно показать, как модель "видит" данные.