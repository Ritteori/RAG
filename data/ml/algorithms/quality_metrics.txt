4. Метрики качества 
31.Какие метрики используются для задач классификации? 
В задачах классификации используются такие метрики: 
• Accuracy — доля правильных предсказаний. 
• Precision — точность (доля правильных среди предсказанных 
положительных). 
• Recall — полнота (доля найденных среди всех истинно положительных). 
• F1-score — гармоническое среднее precision и recall. 
• ROC-AUC — площадь под ROC-кривой, оценивает качество модели при 
разных порогах. 
• PR-AUC — площадь под кривой precision-recall (важно при сильном 
дисбалансе). 
• LogLoss (кросс-энтропия) — учитывает вероятности предсказаний, а не 
только классы. 
• Balanced accuracy, Cohen’s kappa, Matthews correlation coefficient (MCC) 
— устойчивы к дисбалансу классов. 
• Визуальные методы: матрица ошибок, ROC/PR кривые. 
32.Что такое Accuracy и почему она может быть плохой метрикой? 
Accuracy — это доля правильных предсказаний: 
Однако accuracy может быть плохой метрикой в задачах с: 
1. Дисбалансом классов. 
Например, если 95% объектов — класс 0, модель может всегда 
предсказывать класс 0 и получит accuracy = 95%, но при этом вообще не 
будет находить класс 1. 
2. Разной «ценой ошибок». 
В медицине ошибка «не заметить болезнь» (false negative) гораздо хуже, 
чем «ложно диагностировать болезнь» (false positive). Accuracy не 
различает эти ситуации. 
В таких случаях используют Precision, Recall, F1-score, ROC-AUC, PR-AUC — они 
дают более честную картину качества модели. 
33.Что такое Precision, Recall и F1-score? 
Precision (точность): 
Показывает, какая доля объектов, предсказанных как «положительные», 
действительно оказалась положительными. 
Recall (полнота): 
Показывает, какая доля настоящих положительных объектов была найдена 
моделью. 
F1-score: 
Чтобы сбалансировать Precision и Recall, используют их гармоническое среднее: 
1. Арифметическое среднее (F_arith): 
Плюсы: 
• Простое и понятное. 
• Хорошо работает, если Precision и Recall сбалансированы. 
Плюсы: 
• Более чувствительно к высоким значениям. 
• Можно использовать, когда важно поощрять метрики, если хотя бы одна из 
них высокая (редко применяют в классификации). 
Минусы: 
• Сильно «наказывает» метрику, если одна из них близка к нулю. (Но это же и 
плюс, см. ниже.) 
Плюсы: 
• Реально отражает качество модели, требуя баланса между Precision и 
Recall. 
• Если хотя бы одна метрика мала → F1 будет малым, что справедливо. 
• Именно поэтому F1 стал стандартом в ML. 
⚖
️ Сравнение на одном примере: 
Precision = 1.0, Recall = 0.0 
• Farith =0.5 → кажется, что модель «средняя». 
• Fquad ≈0.707 → кажется, что модель «очень хорошая». 
• F1 =0.0 → показывает реальность: модель бесполезна. 
34.Когда лучше использовать Precision, а когда Recall? 
• Precision (точность) важнее, когда ошибки ложноположительных 
предсказаний слишком дороги. 
Пример: фильтрация спама. Если модель ошибётся и примет важное 
письмо за спам → это плохо. Лучше недоотфильтровать, чем удалить ценное 
письмо. 
• Recall (полнота) важнее, когда недопустимо пропустить ни один важный 
случай. 
Пример: диагностика болезней. Пусть будет много ложных 
срабатываний, но мы точно найдём всех пациентов с заболеванием. 
• В реальных задачах обычно стремятся к балансу, используя F1-score или 
Precision-Recall кривые. 
35.Что такое ROC и AUC? 
ROC (Receiver Operating Characteristic) — это график, который показывает 
баланс между: 
• True Positive Rate (TPR, Recall): 
• False Positive Rate (FPR): 
Подковырка: 
ROC и AUC плохо интерпретируются при сильном дисбалансе классов. В таких 
случаях чаще используют PR-кривую (Precision-Recall). 
Важная подковырка: ROC и AUC могут вводить в заблуждение при сильном 
дисбалансе классов. 
В таких ситуациях модель может показывать высокий AUC даже при плохой 
реальной полезности. 
Поэтому в задачах с редкими положительными событиями (например, медицина, 
обнаружение аномалий) часто вместо ROC/AUC строят PR-кривую (Precision
Recall), которая лучше отражает качество работы модели. 
36.Как построить ROC-кривую? 
Как построить ROC-кривую руками (без библиотек): 
1. Есть предсказания модели: у тебя есть вероятность принадлежности к 
положительному классу (например, y_pred_proba) и истинные метки 
(y_true). 
2. Задаём разные пороги (от 0 до 1, например 0.0, 0.1, 0.2 … 1.0). 
3. Для каждого порога считаем метрики: 
a. классифицируем: если вероятность > порога → класс 1, иначе → класс 
0; 
b. считаем TP, FP, TN, FN; 
c. вычисляем 
4. Строим график: по оси X — FPR, по оси Y  TPR. 
5. ROC-кривая — это ломаная линия, проходящая через эти точки (плюс 
начало (0,0) и конец (1,1)). 

37.Какие метрики применяются для регрессии? 
39.Что такое R² (коэффициент детерминации)? 
Коротко 
R2 показывает долю дисперсии (вариации) отклика y, которую объясняет 
модель. Значение лежит “обычно” в [0,1] — чем ближе к 1, тем лучше модель 
объясняет разброс данных. Формулы: 
Что это значит интуитивно 
• TSS — сколько в данных вообще «колебаний» (вариации) относительно 
среднего. 
• SSR — какая часть этой вариации объясняется моделью (отклонения 
предсказаний от среднего). 
• SSE — какая часть остаётся необъяснённой (ошибки). 
• R2=SSR/TSS — доля объяснённой вариации. 
Если R2=0.8, то модель объясняет 80% дисперсии y, 20% остаётся 
необъяснённым. 
Ограничения и «подковырки» (важно) 
1. R² не показывает, правильно ли модель предсказывает на новых 
данных. Высокий R2 на train может быть следствием переобучения — 
всегда проверяйте на валидации/CV. 
2. R² не означает причинности. Высокая доля объяснённой вариации — не 
доказательство причинно-следственной связи. 
3. Чувствителен к выбросам. Большие ошибки (outliers) могут сильно 
изменить R2. 
4. Нельзя напрямую сравнивать R2 между моделями с разными целевыми 
величинами или разными датасетами. 
5. В некоторых моделях (без интерсепта) интерпретация R² меняется. 
Стандартная формула предполагает сравнение с моделью-константой 
(средним), так что при отсутствии intercept нужно быть аккуратным. 
6. При сильном нелинейном зависимости линейный R2 будет низким, хотя 
нерегрессия по другому базису (полином, трансформация) может 
объяснить многое. 
7. R² может быть низким, но модель всё равно полезна — например, если 
прогнозы точны для редких, но критичных случаев. 
Практика: что использовать вместе с R2 
• Для оценки абсолютной ошибки — MAE / RMSE (дают масштаб ошибки в тех 
же единицах). 
• Для сравнения моделей с разным числом признаков — adjusted R2. 
• Для оценки обобщающей способности — кросс-валидация (CV) и CV
оценки R2 или RMSE. 
• Для проверки гипотез о значимости модели — F-тест (в рамках линейной 
регрессии). 
40.Как интерпретировать R²? 
Базовая интерпретация 
• R2 показывает долю дисперсии целевой переменной y, объяснённой 
моделью. 
• Значения: 
o R2=1 → модель идеально предсказывает данные (все точки на линии 
предсказаний). 
o R2=0 → модель не лучше, чем константное предсказание среднего yˉ . 
o R2<0 → модель хуже, чем просто предсказывать среднее (например, 
при сильном переобучении или полном рассогласовании). 
Примеры интерпретации 
R2=0.85: модель объясняет 85% вариации отклика, остаётся 15% 
«шумовой» или неуловимой части. 
• R2=0.2: модель объясняет лишь 20% дисперсии, значит либо признаки 
слабые, либо модель слишком простая. 
• R2=−0.5: модель хуже, чем тупое среднее. Нужно проверить ошибки в 
данных, признаки или саму модель. 
Подковырки (часто путают!) 
1. Высокий R2 ≠ хорошая модель. 
Он может быть высоким из-за переобучения или коррелированных 
признаков. На тестовых данных качество может падать. 
2. Низкий R2 ≠ плохая модель. 
В социальных/медицинских науках даже R2=0.2 может считаться отличным 
результатом — мир слишком шумный. 
В физике же R2=0.95 может быть «плохо». 
3. Зависит от области применения. 
a. В задачах прогнозирования финансовых рынков R2=0.1 может быть 
супер полезным. 
b. В задачах инженерного моделирования нужен минимум R2≈0.9. 
4. Нельзя напрямую сравнивать R2 между разными датасетами. 
Масштаб и разброс данных влияют на величину TSS, а значит и на сам 
коэффициент. 
5. Нелинейность: 
Линейная регрессия может давать низкий R2 даже при сильной 
нелинейной зависимости. Нужны полиномы, сплайны, деревья и т. д. 
Как правильно интерпретировать в работе 
• Используй R2 вместе с другими метриками (MAE, RMSE, CV-оценки). 
• Если сравниваешь модели с разным количеством признаков → смотри на 
adjusted R2. 
• Смотри на тестовые/валидационные данные — на трейне R2 всегда будет 
выше. 
Итог: 
R2 — это показатель того, какую долю изменчивости отклика модель может 
объяснить. Но он не гарантирует, что модель будет полезной или обобщающей. 
Всегда нужно интерпретировать его в контексте задачи и сравнивать с базовыми 
моделями.