30.Какие параметры важны при настройке деревьев и ансамблей? 
Важные параметры для деревьев решений 
1. max_depth — максимальная глубина дерева. 
a. Малое значение → недообучение. 
b. Большое значение → переобучение (листья с 1 объектом). 
c. Подковырка: иногда лучше ограничить не глубину напрямую, а 
размер листа, чтобы дерево само решало, как глубоко расти. 
2. min_samples_split — минимальное количество объектов, чтобы узел 
делился. 
a. Если мало → дерево строит много маленьких веток (оверфит). 
b. Если много → дерево "ленится" делиться и может недообучиться. 
3. min_samples_leaf — минимальное количество объектов в листе. 
a. Подковырка: при дисбалансе классов стоит ставить большее 
значение, чтобы листья не содержали "шумные" редкие объекты. 
4. criterion — функция качества: 
a. Gini или Entropy для классификации. 
b. MSE или MAE для регрессии. 
c. Подковырка: разница между Gini и Entropy часто минимальна, но при 
очень несбалансированных данных Entropy может быть 
чувствительнее. 
Важные параметры для ансамблей (RF, GBM, XGBoost и т.п.) 
1. n_estimators — количество деревьев. 
a. Random Forest: больше деревьев почти всегда лучше, но дольше и 
больше памяти. 
b. Boosting: слишком много деревьев = оверфит (особенно при 
большом learning_rate). 
2. max_features — сколько признаков использовать при разбиении. 
a. В Random Forest уменьшает корреляцию между деревьями (важно 
для устойчивости). 
b. Подковырка: маленькое значение увеличивает разброс → помогает 
снизить оверфит, но может повысить variance. 
3. bootstrap (для RF) — брать ли объекты с возвращением. 
a. Даёт "разнообразие" деревьям. 
4. learning_rate (для бустинга) — шаг "обновления". 
a. Малый → нужен большой n_estimators, но обучение устойчивее. 
b. Большой → быстрое обучение, но риск переобучения. 
5. max_depth / min_child_weight / subsample (в XGBoost/LightGBM). 
a. Это дополнительные ручки против оверфита. 
b. Подковырка: иногда лучше контролировать именно объем данных 
для каждого дерева, чем глубину дерева. 
Главное: для деревьев параметры = контроль переобучения конкретного 
дерева, 
а для ансамблей = баланс "слабая модель + количество + шаг обучения".