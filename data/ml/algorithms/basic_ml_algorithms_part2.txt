6. Что такое bias-variance tradeoff? 
Определение: 
• Bias-variance tradeoff — это баланс между смещением (bias) и вариансом 
(variance) модели, который стремится к оптимальному результату для 
задачи. Это компромисс, поскольку уменьшение одного из этих факторов 
часто приводит к увеличению другого. 
Bias (смещение): 
• Определение: Смещение — это ошибка, которая возникает, когда модель 
слишком упрощена и не может точно описать зависимость в данных. 
• Признак: Когда модель имеет высокое смещение, она недообучена 
(underfitting). Модель не может захватить сложные паттерны и делает 
грубые, неточные предсказания. 
• Пример: Линейная регрессия, использующая одну переменную для 
предсказания, когда существует сложная зависимость между признаками 
и целевой переменной. 
Variance (варианс): 
• Определение: Варианс — это ошибка, которая возникает, когда модель 
слишком сложная и слишком чувствительна к малым изменениям в 
обучающих данных. 
• Признак: Когда модель имеет высокий варианс, она переобучается 
(overfitting). Модель запоминает данные, но плохо обобщает на новые, 
невиденные примеры. 
• Пример: Глубокая нейросеть, которая идеально предсказывает 
тренировочные данные, но плохо работает на тестовых. 
Баланс: 
• Идеальная модель: Для достижения хороших предсказаний модель 
должна сбалансировать как смещение, так и варианс. Это означает, что 
нужно минимизировать оба этих показателя. 
• Что происходит, если мы уменьшаем bias: Уменьшение смещения может 
привести к увеличению варианса, то есть модель начнёт переобучаться. 
• Что происходит, если мы уменьшаем variance: Уменьшение варианса 
может привести к увеличению смещения, то есть модель станет слишком 
простой. 
Как это работает: 
• Цель: Нахождение такой модели, которая будет достаточно сложной, 
чтобы захватить основные закономерности, но при этом не будет настолько 
сложной, чтобы "запоминать" данные и не обобщать. 
7. Что такое кросс-валидация? 
Определение: 
• Кросс-валидация — это метод, используемый для оценки 
производительности модели. Он состоит в том, что данные разбиваются 
на несколько фолдов (подмножеств), и модель обучается и проверяется 
несколько раз, чтобы убедиться, что она хорошо обобщает на разных 
подмножествах данных. 
Процесс: 
1. Разбиение на фолды: Данные разбиваются на N фолдов (например, 5 или 
10). 
2. Обучение и валидация: Для каждого фолда: 
a. Модель обучается на N-1 фолдах (тренировочная часть). 
b. Оставшийся фолд используется для валидации модели. 
3. Повторение: Этот процесс повторяется, пока каждый фолд не будет 
использован для валидации. 
Преимущества: 
• Каждая часть данных используется и для обучения, и для тестирования 
модели. 
• Это позволяет получить более надежную оценку производительности 
модели и избежать выбора данных, которые могли бы привести к 
переобучению или недообучению. 
Пример с 5 фолдами: 
• Разделим данные на 5 фолдов. 
• 1-й фолд — валидация, остальные 4 — обучение. 
• Во 2-й итерации 2-й фолд — валидация, остальные 4 — обучение. 
• И так далее, пока каждый фолд не побывает в качестве валидационного. 
Виды кросс-валидации: 
1. K-Fold: Обычный метод кросс-валидации, где данные разбиваются на N 
равных частей (фолдов). 
2. Stratified K-Fold: Используется для классификации, где важно сохранить 
пропорции классов в каждом фолде. Это особенно полезно, если классы 
не сбалансированы. 
3. Leave-One-Out (LOO): Каждый фолд состоит из одного примера, что 
идеально для маленьких наборов данных. 
8. Для чего нужен train/test split? 
Определение: 
• Train/test split — это процесс разделения исходных данных на две части: 
обучающую (train) и тестовую (test). 
• Это делается для того, чтобы модель обучалась на одном наборе данных, а 
затем тестировалась на новых данных, которые она не видела во время 
обучения. 
Зачем это нужно? 
1. Предотвращение переобучения (overfitting): Если модель обучается и 
тестируется на одном и том же наборе данных, то её точность будет 
завышена, потому что она будет "запоминать" тренировочные данные, а не 
обобщать. 
2. Оценка производительности модели: Разделяя данные на train и test, мы 
можем получить объективную оценку того, как модель будет работать на 
новых, невидимых данных. 
3. Общие практики: Обычно в ML используется разделение на 80/20 или 
70/30 для обучающих и тестовых данных, чтобы гарантировать, что модель 
будет проверяться на достаточном количестве данных. 
Процесс: 
1. Разделение: Данные случайным образом разделяются на две части: одну 
для обучения, другую для тестирования. 
2. Обучение: Модель обучается только на train данных. 
3. Тестирование: Модель проверяется на test данных, которые она не видела 
до этого. 
Важно: 
• Иногда данные могут быть дополнительно разбиты на валидационную 
(validation) выборку для выбора гиперпараметров модели, например, через 
k-fold cross-validation. 
9. Что такое функция потерь и зачем она нужна? 
Определение: 
• Функция потерь (или loss function) — это математическое выражение, 
которое измеряет разницу между предсказаниями модели и реальными 
значениями (таргетами). 
• Функция потерь даёт оценку того, насколько хороша модель на текущем 
шаге. В ходе обучения модель пытается минимизировать эту функцию, 
чтобы улучшить свои предсказания. 
Роль функции потерь: 
• Функция потерь помогает в процессе обучения модели, так как она служит 
ориентиром для оптимизации параметров модели. 
• На основе функции потерь вычисляется градиент (частная производная), 
который показывает, в каком направлении необходимо изменить 
параметры модели, чтобы уменьшить ошибку. 
Пример: 
• Допустим, у нас есть сверточный слой с 27000+1000 параметров. Для 
оптимизации этих параметров на каждом шаге мы вычисляем градиенты 
функции потерь. Это позволяет понять, в какую сторону корректировать 
веса, чтобы ошибка модели (потери) уменьшалась. 
Основные функции потерь: 
1. MSE (Mean Squared Error) — для регрессии, измеряет квадрат разницы 
между предсказанными и реальными значениями. 
2. MAE (Mean Absolute Error) — для регрессии, измеряет абсолютную разницу 
между предсказанными и реальными значениями. 
3. BCE (Binary Cross-Entropy) — для бинарной классификации, измеряет 
ошибку в предсказаниях двух классов. 
4. CE (Cross-Entropy) — для многоклассовой классификации, измеряет 
ошибку между предсказаниями и истинными метками. 
5. Huber Loss — комбинирует MSE и MAE, наказывается за большие ошибки, 
но менее чувствителен к выбросам. 
6. Dice Loss — используется для задач сегментации, измеряет схожесть 
между предсказанными и истинными масками. 
Как работает оптимизация: 
• В процессе обучения мы минимизируем функцию потерь с помощью 
алгоритма оптимизации (например, градиентный спуск). 
• Мы рассчитываем градиенты функции потерь по параметрам модели, 
затем обновляем эти параметры, чтобы уменьшить ошибку. 
10.Что такое метрики качества модели? 
Определение: 
• Метрики качества модели — это числовые показатели, которые 
позволяют оценить, насколько хорошо модель выполняет свою задачу. 
Они могут зависеть от типа задачи (классификация, регрессия, детекция и 
т.д.). 
Метрики для классификации: 
1. Accuracy (Точность) — процент правильных предсказаний из всех. 
a. Недостаток: Для несбалансированных классов может быть 
неинформативной, так как она не учитывает распределение 
классов. 
2. Precision (Точность) — доля правильных положительных предсказаний 
среди всех предсказанных положительных. 
a. Это важная метрика, когда важно минимизировать ложные 
срабатывания (например, в медицинских тестах). 
3. Recall (Полнота) — доля правильно предсказанных положительных среди 
всех истинных положительных. 
a. Это важная метрика, когда важен покрытие всех положительных 
примеров (например, в задачах поиска объектов). 
4. F1-Score — гармоническое среднее между precision и recall. 
Используется, когда нужно сбалансировать эти две метрики. 
a. F1-Score лучше использовать, когда важен баланс между точностью 
и полнотой. 
5. ROC-AUC (Area Under the ROC Curve) — площадь под кривой, 
показывающей зависимость между истинной положительной и ложной 
положительной скоростью при разных порогах. 
a. Это метрика, которая оценивает качество классификатора в целом, 
независимо от порога, и полезна для оценки бинарных 
классификаторов. 
6. Confusion Matrix (Матрица ошибок) — таблица, которая отображает 
количество истинных положительных, истинных отрицательных, ложных 
положительных и ложных отрицательных предсказаний. 
Метрики для детекции объектов: 
• IoU (Intersection over Union) — метрика, измеряющая сходство между 
предсказанным и истинным боксовыми ограничениями. Чем выше IoU, тем 
точнее модель предсказывает местоположение объектов. 
Метрики для сегментации: 
• IoU также используется для оценки качества сегментации. 
• Dice Coefficient — это метрика, которая измеряет сходство между 
предсказанными и истинными масками. 
Метрики для генеративных моделей: 
• FID (Frechet Inception Distance) — метрика, используемая для измерения 
сходства между реальными и сгенерированными изображениями. 
Визуальная проверка: 
• Визуализация результатов — это важный инструмент для проверки 
качества работы модели, особенно для задач с изображениями. Иногда 
результаты невозможно оценить только по метрикам, и полезно визуально 
проверить, насколько модель предсказала корректно.