4. Что такое полносвязный слой (Fully-Connected / Dense Layer)?  
Что это? Это слой, в котором каждый нейрон соединен с каждым выходом 
предыдущего слоя. Это классический, базовый строительный блок нейронных сетей. 
Как работает математически: 
• Выполняет операцию линейного преобразования: y = Wx + b 
o x — вектор входа (выходы с предыдущего слоя) 
o W — матрица весов 
o b — вектор смещений 
o y — вектор выхода 
• По-русски: каждый нейрон слоя вычисляет взвешенную сумму всех входов и 
добавляет смещение. 
Зачем он нужен и где используется? 
1. Обобщение признаков (Feature Integration): Как ты верно подметил, его 
главная роль — "обобщение". После того как предыдущие слои (например, 
сверточные) выделили локальные низкоуровневые признаки (углы, текстуры), 
полносвязный слой комбинирует их, чтобы предсказать более сложные, 
глобальные понятия (например, "это ухо", "это глаз"). 
2. Классификатор в конце сети: Чаще всего последний полносвязный слой 
используется как классификатор. Количество его нейронов равно числу классов, 
а выходы обычно подаются на функцию активации Softmax для получения 
вероятностей. 
Аналогия: Представьте, что у вас есть команда экспертов (предыдущий слой): 
• Один эксперт знает всё про "полосатость" 
• Другой — про "оранжевый цвет" 
• Третий — про "четыре ноги" 
Полносвязный слой — это "руководитель", который выслушивает всех экспертов, 
взвешивает их мнения (Wx) и на основе этого принимает итоговое решение: "Да, это 
тигр" (y). 
Важный нюанс: Хотя само преобразование Wx + b — линейное, полносвязные слои 
почти всегда используются в паре с нелинейной функцией активации (ReLU и др.). 
Именно эта комбинация (Linear -> Activation) позволяет сети обучаться нелинейным 
зависимостям. 
5. Как работает обратное распространение ошибки (Backpropagation)? 
Объясни интуицию.  
Интуиция: Backpropagation — это эффективный алгоритм для вычисления градиента 
(то есть вектора частных производных) сложной функции потерь относительно всех 
параметров (весов и смещений) нейронной сети. Он делает обучение сетей с 
миллионами параметров практически возможным. 
Как это работает (шаги): 
1. Прямой проход (Forward Pass): 
a. Данные проходят через сеть от входа к выходу. 
b. На каждом слое вычисляется взвешенная сумма и применяется функция 
активации. 
c. На выходе сравнивается с правильным ответом и вычисляется значение 
функции потерь L. 
2. Обратный проход (Backward Pass): 
a. Цель: Понять, "кто виноват" в ошибке, и в какой степени. Мы 
вычисляем, как каждый вес и смещение в сети повлияли на итоговую 
ошибку L. 
b. Сначала для выходного слоя: Мы вычисляем градиент ошибки по 
весам выходного слоя. Это просто, так как мы знаем, насколько наш 
вывод отличается от истины. 
c. Затем для скрытых слоев (самая важная часть): Здесь в игру вступает 
цепное правило дифференцирования (chain rule). 
i. Мы используем градиенты от следующего (более близкого к 
выходу) слоя, чтобы вычислить градиенты для предыдущего. 
ii. Проще говоря, мы спрашиваем: "Окей, я знаю, как ошибка 
изменилась из-за нейронов следующего слоя. А как эти нейроны, 
в свою очередь, изменились из-за моих весов?". 
d. Алгоритм проходит таким образом обратно через все слои, от выхода ко 
входу, эффективно распределяя "вину" за ошибку по всем весам. 
Простая аналогия: Представьте, что вы управляющий заводом (функция потерь), и 
выпуск бракованной продукции (высокая ошибка) — это плохо. 
• Forward Pass — это производственный процесс от цеха А к цеху Z. 
• Backward Pass — это когда вы, обнаружив брак, идете обратно по цехам (Z -> 
Y -> ... -> A) и спрашиваете каждого начальника цеха: "Насколько твои 
действия повлияли на этот брак, исходя из того, что передал тебе следующий 
цех?". 
• Обновление весов — это выговор и инструктаж для каждого начальника, 
основанный на его "вине". 
Итог: Backpropagation — это не метод обучения сам по себе, а сердцевина 
градиентного спуска для нейросетей, которая вычисляет направление для обновления 
весов. 
6. Что такое оптимизаторы? Чем SGD отличается от Adam? 
Что такое оптимизатор? Это алгоритм, который определяет, как именно обновлять 
веса модели на основе рассчитанных градиентов, чтобы минимизировать функцию 
потерь. Его цель — найти минимум быстрее и стабильнее. 
SGD (Stochastic Gradient Descent) 
• Формула обновления: w = w - η * ∇L(w) 
o η (eta) — скорость обучения (learning rate) 
o ∇L(w) — градиент функции потерь по весам 
• Как работает: Делает шаг строго в направлении, противоположном текущему 
градиенту. 
• Проблемы: 
o Может "осциллировать" вокруг минимума, особенно если learning rate 
велик. 
o Не учитывает "историю" градиентов, поэтому может быть медленным в 
областях с маленьким, но постоянным уклоном. 
Adam (Adaptive Moment Estimation) 
Adam сочетает в себе две ключевые идеи: 
1. Momentum (Инерция): 
a. Вместо того чтобы смотреть только на текущий градиент, Adam 
учитывает экспоненциальное скользящее среднее прошлых градиентов 
(m_t). 
b. Это помогает "разгоняться" в направлениях, где градиенты сохраняют 
знак, и подавлять колебания. Именно это ты описал словами "двигаться 
туда быстрее". 
2. Адаптивный learning rate (RMSProp): 
a. Adam также вычисляет экспоненциальное скользящее среднее 
квадратов градиентов (v_t). 
b. Это позволяет адаптивно настраивать learning rate для каждого 
параметра отдельно. Параметры с большими историческими 
градиентами получают меньший эффективный learning rate, и наоборот. 
Это стабилизирует обучение. 
Ключевые отличия: 
Критерий 
SGD 
Adam 
Скорость 
сходимости Медленнее 
Стабильнос
ть 
Может колебаться 
Быстрее (за счет момента) 
Более стабилен (за счет 
адаптивного LR) 
Learning 
Rate 
Единый для всех весов 
Индивидуальный для каждого 
веса 
Гиперпара
метры 
Проще (в основном η) 
Сложнее (η, β₁, β₂, ε) 
Область 
применени
я 
Часто дает лучшее обобщение 
при тонкой настройке 
Стандарт по умолчанию, 
работает хорошо "из коробки" 
Практический вывод: 
• Adam — отличный выбор по умолчанию для большинства задач, он сходится 
быстро и стабильно. 
• SGD (часто с Momentum) — может потребовать больше настройки, но иногда 
позволяет достичь лучшего финального качества (обобщения) в задачах 
компьютерного зрения. 
7. Почему важно инициализировать веса, а не задавать их нулями? 
(Проблема симметрии). 
Представьте, что все веса в нейронах одного слоя установлены в ноль. 
1. Проблема на Прямом Проходе (Forward Pass): 
• Все нейроны внутри одного слоя будут вычислять одинаковый выход. Если W 
= 0, то z = Wx + b = b. Если и смещения (b) инициализированы нулями или 
одинаково, то все нейроны выдадут абсолютно одинаковый результат. 
• Сеть не сможет извлечь никаких полезных признаков, так как все "эксперты" в 
одном слое делают одно и то же. 
2. Фатальная проблема на Обратном Проходе (Backpropagation) — "Симметрия": 
• Это главная проблема. Поскольку все нейроны в слое получили одинаковые 
входы и выдали одинаковые выходы, то и градиенты, вычисленные для их 
весов, будут идентичными. 
• В результате, все веса в этом слое обновятся одинаково. 
• На следующей итерации ситуация повторится: нейроны снова будут вычислять 
одинаковые выходы, получать одинаковые градиенты и обновляться одинаково. 
• Итог: Нейроны никогда не смогут специализироваться. Веса в одном слое так и 
останутся одинаковыми, и вся сеть по сути будет работать как один большой 
нейрон. Это и есть "проблема симметрии" — сеть не может выйти из 
состояния симметрии, в которое мы ее поместили. 
Аналогия: Представьте, что вы набрали команду из 10 стажеров (нейроны в слое) и 
дали им одно и то же задание. Но в итоге: 
1. Они все сделают работу абсолютно одинаково (прямой проход). 
2. Начальник даст им всем один и тот же фидбэк (одинаковый градиент). 
3. Они все исправят ошибки одинаково (одинаковое обновление весов). В итоге вы 
получите 10 клонов, а не команду разнообразных специалистов. Эффективность 
команды будет крайне низкой. 
Как решают эту проблему? 
Веса нужно инициализировать маленькими случайными числами, чтобы "сломать" 
начальную симметрию. Это гарантирует, что нейроны начнут обучение с разных 
"стартовых позиций" и будут специализироваться на разных признаках. 
Правильные методы инициализации: 
1. Xavier/Glorot Initialization: Хорошо подходит для слоев с сигмоидой или 
гиперболическим тангенсом. Идея: дисперсия выходов и градиентов каждого 
слоя должна быть одинаковой. Веса инициализируются случайными 
значениями из диапазона, пропорционального 1 / sqrt(n_in), где n_in — 
количество входов нейрона. 
2. He Initialization: Стандарт для слоев с ReLU и ее вариациями. Работает лучше, 
чем Xavier, для этих функций, т.к. учитывает, что ReLU "отсекает" половину 
активаций. Веса инициализируются случайными значениями с дисперсией 2 / 
n_in. 
Практический итог: Случайная инициализация — это не просто "так принято", а 
необходимое условие для того, чтобы градиентный спуск вообще мог работать. Она 
обеспечивает начальное разнообразие нейронов, которое в процессе обучения 
превращается в их полезную специализацию. 
Современные фреймворки (PyTorch, TensorFlow) по умолчанию используют умные 
методы инициализации (например, He для сверточных слоев с ReLU), так что вам не 
нужно делать это вручную, но понимать причину — обязательно.